{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "#     Random walk generator\n",
    "\n",
    "#     Author:\n",
    "#         Zeyu Li <zyli@cs.ucla.edu> or <zeyuli@ucla.edu>\n",
    "\n",
    "#     Description:\n",
    "#         Generating random walks on our Uq, Ua, and Q network using NetworkX.\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "# import os, sys\n",
    "# import networkx as nx\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import math\n",
    "\n",
    "# from collections import Counter\n",
    "# import itertools\n",
    "\n",
    "\n",
    "\n",
    "# class MetaPathGenerator:\n",
    "#     \"\"\"MetaPathGenerator\n",
    "\n",
    "#     Args:\n",
    "#         dataset     - the dataset to work on\n",
    "#         length      - the length of random walks to be generated\n",
    "#         num_walks   - the number of random walks start from each node\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, dataset, length=100, coverage=10000):\n",
    "#         self._walk_length = length\n",
    "#         self._coverage = coverage\n",
    "#         self._dataset = dataset\n",
    "#         self.G = nx.Graph()\n",
    "\n",
    "#         self.walks = []\n",
    "#         self.pairs = []\n",
    "\n",
    "#         self.initialize()\n",
    "\n",
    "#     def initialize(self):\n",
    "#         \"\"\" Initialize Graph\n",
    "\n",
    "#         Initialize graph with Uq-Q pairs and Q-Ua pairs.\n",
    "#         We use following Uppercase letter\n",
    "\n",
    "#         Args:\n",
    "#             QR_file - Input file containing Q-R pairs\n",
    "#             QA_file - Input file containing Q-A pairs\n",
    "\n",
    "#         \"\"\"\n",
    "\n",
    "#         DATA_DIR = os.getcwd() + \"/data/parsed/\" + self._dataset + \"/\"\n",
    "#         QR_file = DATA_DIR + \"Q_R.txt\"\n",
    "#         QA_file = DATA_DIR + \"Q_A.txt\"\n",
    "#         G = self.G\n",
    "#         # Read in Uq-Q pairs\n",
    "#         with open(QR_file, \"r\") as fin:\n",
    "#             lines = fin.readlines()\n",
    "#             RQ_edge_list = []\n",
    "#             for line in lines:\n",
    "#                 unit = line.strip().split()\n",
    "#                 RQ_edge_list.append([\"Q_\" + unit[0],\n",
    "#                                      \"R_\" + unit[1]])\n",
    "#             G.add_edges_from(RQ_edge_list)\n",
    "#         with open(QA_file, \"r\") as fin:\n",
    "#             lines = fin.readlines()\n",
    "#             QA_edge_list = []\n",
    "#             for line in lines:\n",
    "#                 unit = line.strip().split()\n",
    "#                 QA_edge_list.append([\"Q_\" + unit[0],\n",
    "#                                      \"A_\" + unit[1]])\n",
    "#             G.add_edges_from(QA_edge_list)\n",
    "\n",
    "#     def get_nodelist(self, type=None):\n",
    "#         \"\"\" Get specific type or all nodes of nodelist in the graph\n",
    "\n",
    "#         Args:\n",
    "#             type - The entity type of the entity.\n",
    "#                    If set as `None`, then all types of nodes would be returned.\n",
    "\n",
    "#         Return:\n",
    "#             nodelist - the list of node with `type`\n",
    "#         \"\"\"\n",
    "#         G = self.G\n",
    "\n",
    "#         if not G.number_of_edges() or not G.number_of_nodes():\n",
    "#             sys.exit(\"Graph should be initialized before get_nodelist()!\")\n",
    "\n",
    "#         if not type:\n",
    "#             return list(G.nodes)\n",
    "#         return [node for node in list(G.nodes)\n",
    "#                 if node[0] == type]\n",
    "\n",
    "#     def generate_metapaths(self, patterns, alpha):\n",
    "#         \"\"\" Generate Random Walk\n",
    "\n",
    "#         Generating random walk from the Tripartite graph\n",
    "#         A candidate pattern pool is:\n",
    "#             \"A-Q-R-Q-A\": specifies 2 A's answered a question proposed by a same R\n",
    "#             \"A-Q-A\": speficies 2 A' answered a same question\n",
    "\n",
    "#         Args:\n",
    "#             meta_pattern - the pattern that guides the walk generation\n",
    "#             alpha - probability of restart\n",
    "\n",
    "#         Return:\n",
    "#             walks - a set of generated random walks\n",
    "#         \"\"\"\n",
    "#         G = self.G\n",
    "#         num_walks, walk_len = self._coverage, self._walk_length\n",
    "#         rand = random.Random(0)\n",
    "\n",
    "#         print(\"Generating Meta-paths ...\")\n",
    "\n",
    "#         if not G.number_of_edges() or not G.number_of_nodes():\n",
    "#             sys.exit(\"Graph should be initialized before generate_walks()!\")\n",
    "\n",
    "#         walks = []\n",
    "\n",
    "#         for meta_pattern in patterns:  # Generate by patterns\n",
    "#             print(\"\\tNow generating meta-paths from pattern: \\\"{}\\\" ...\"\n",
    "#                   .format(meta_pattern))\n",
    "#             start_entity_type = meta_pattern[0]\n",
    "#             start_node_list = self.get_nodelist(start_entity_type)\n",
    "#             for cnt in range(num_walks):  # Iterate the node set for cnt times\n",
    "#                 print(\"Count={}\".format(cnt))\n",
    "#                 rand.shuffle(start_node_list)\n",
    "#                 total = len(start_node_list)                \n",
    "#                 for ind, start_node in enumerate(start_node_list):\n",
    "#                     if ind % 3000 == 0:\n",
    "#                         print(\"Finished {:.2f}\".format(ind/total))\n",
    "\n",
    "#                     walks.append(\n",
    "#                         self.__meta_path_walk(\n",
    "#                             start=start_node,\n",
    "#                             alpha=alpha,\n",
    "#                             pattern=meta_pattern))\n",
    "\n",
    "#         print(\"Done!\")\n",
    "#         self.walks = walks\n",
    "#         return\n",
    "\n",
    "#     def generate_metapaths_2(self):\n",
    "#         \"\"\" Generate Random Walk\n",
    "\n",
    "#         Generating random walk from the Tripartite graph\n",
    "#         Args:\n",
    "#             meta_pattern - the pattern that guides the walk generation\n",
    "#             alpha - probability of restart\n",
    "\n",
    "#         Return:\n",
    "#             walks - a set of generated random walks\n",
    "#         \"\"\"\n",
    "#         G = self.G\n",
    "#         num_walks, walk_len = self._coverage, self._walk_length\n",
    "#         rand = random.Random(0)\n",
    "\n",
    "#         print(\"Generating Meta-paths ...\")\n",
    "\n",
    "#         if not G.number_of_edges() or not G.number_of_nodes():\n",
    "#             sys.exit(\"Graph should be initialized before generate_walks()!\")\n",
    "\n",
    "#         walks = []\n",
    "\n",
    "#         print(\"\\tNow generating meta-paths from deepwalk ...\")\n",
    "#         start_node_list = self.get_nodelist()\n",
    "#         for cnt in range(num_walks):  # Iterate the node set for cnt times\n",
    "#             print(\"Count={}\".format(cnt))\n",
    "#             rand.shuffle(start_node_list)\n",
    "#             total = len(start_node_list)\n",
    "#             for ind, start_node in enumerate(start_node_list):\n",
    "#                 if ind % 3000 == 0:\n",
    "#                     print(\"Finished {:.2f}\".format(ind/total))\n",
    "#                 walks.append(\n",
    "#                     self.__random_walk(start=start_node))\n",
    "\n",
    "#         print(\"Done!\")\n",
    "#         self.walks = walks\n",
    "#         return\n",
    "\n",
    "#     def __random_walk(self, start=None):\n",
    "#         \"\"\"Single Random Walk Generator\n",
    "\n",
    "#         Args:\n",
    "#             rand - an random object to generate random numbers\n",
    "#             start - starting node\n",
    "\n",
    "#         Return:\n",
    "#             walk - the single walk generated\n",
    "#         \"\"\"\n",
    "#         G = self.G\n",
    "#         rand = random.Random()\n",
    "#         walk = [start]\n",
    "#         cur_node = start\n",
    "#         while len(walk) <= self._walk_length:\n",
    "#             possible_next_nodes = [neighbor\n",
    "#                                    for neighbor in G.neighbors(cur_node)]\n",
    "#             next_node = rand.choice(possible_next_nodes)\n",
    "#             walk.append(next_node)\n",
    "#             cur_node = next_node\n",
    "\n",
    "#         return \" \".join(walk)\n",
    "\n",
    "#     def __meta_path_walk(self, start=None, alpha=0.0, pattern=None):\n",
    "#         \"\"\"Single Walk Generator\n",
    "\n",
    "#         Generating a single random walk that follows a meta path of `pattern`\n",
    "\n",
    "#         Args:\n",
    "#             rand - an random object to generate random numbers\n",
    "#             start - starting node\n",
    "#             alpha - probability of restarts\n",
    "#             pattern - (string) the pattern according to which to generate walks\n",
    "#             walk_len - (int) the length of the generated walk\n",
    "\n",
    "#         Return:\n",
    "#             walk - the single walk generated\n",
    "\n",
    "#         \"\"\"\n",
    "#         def type_of(node_id):\n",
    "#             return node_id[0]\n",
    "\n",
    "#         rand = random.Random()\n",
    "#         # Checking pattern is correctly initialized\n",
    "#         if not pattern:\n",
    "#             sys.exit(\"Pattern is not specified when generating meta-path walk\")\n",
    "\n",
    "#         G = self.G\n",
    "#         n, pat_ind = 1, 1\n",
    "\n",
    "#         walk = [start]\n",
    "\n",
    "#         cur_node = start\n",
    "\n",
    "#         # Generating meta-paths\n",
    "#         while len(walk) <= self._walk_length or pat_ind != len(pattern):\n",
    "\n",
    "#             # Updating the pattern index\n",
    "#             pat_ind = pat_ind if pat_ind != len(pattern) else 1\n",
    "\n",
    "#             # Decide whether to restart\n",
    "#             if rand.random() >= alpha:\n",
    "#                 # Find all possible next neighbors\n",
    "#                 possible_next_node = [neighbor\n",
    "#                                       for neighbor in G.neighbors(cur_node)\n",
    "#                                       if type_of(neighbor) == pattern[pat_ind]]\n",
    "#                 # Random choose next node\n",
    "#                 next_node = rand.choice(possible_next_node)\n",
    "#             else:\n",
    "#                 next_node = walk[0]\n",
    "\n",
    "#             walk.append(next_node)\n",
    "#             cur_node = next_node\n",
    "#             pat_ind += 1\n",
    "\n",
    "#         return \" \".join(walk)\n",
    "\n",
    "#     def write_metapaths(self):\n",
    "#         \"\"\"Write Metapaths to files\n",
    "\n",
    "#         Args:\n",
    "#             walks - The walks generated by `generate_walks`\n",
    "#         \"\"\"\n",
    "\n",
    "#         print(\"Writing Generated Meta-paths to files ...\", end=\" \")\n",
    "\n",
    "#         DATA_DIR = os.getcwd() + \"/metapath/\"\n",
    "#         OUTPUT = DATA_DIR + self._dataset + \"_\" \\\n",
    "#                  + str(self._coverage) + \"_\" + str(self._walk_length) + \".txt\"\n",
    "#         if not os.path.exists(DATA_DIR):\n",
    "#             os.mkdir(DATA_DIR)\n",
    "#         with open(OUTPUT, \"w\") as fout:\n",
    "#             for walk in self.walks:\n",
    "#                 print(\"{}\".format(walk), file=fout)\n",
    "\n",
    "#         print(\"Done!\")\n",
    "\n",
    "#     def path_to_pairs(self, window_size):\n",
    "#         \"\"\"Convert all metapaths to pairs of nodes\n",
    "\n",
    "#         Args:\n",
    "#             walks - all the walks to be translated\n",
    "#             window_size - the sliding window size\n",
    "#         Return:\n",
    "#             pairs - the *shuffled* pair corpus of the dataset\n",
    "#         \"\"\"\n",
    "#         pairs = []\n",
    "#         if not self.walks:\n",
    "#             sys.exit(\"Walks haven't been created.\")\n",
    "#         for walk in self.walks:\n",
    "#             walk = walk.strip().split(' ')\n",
    "#             for pos, token in enumerate(walk):\n",
    "#                 lcontext, rcontext = [], []\n",
    "#                 lcontext = walk[pos - window_size: pos] \\\n",
    "#                     if pos - window_size >= 0 \\\n",
    "#                     else walk[:pos]\n",
    "\n",
    "#                 if pos + 1 < len(walk):\n",
    "#                     rcontext = walk[pos + 1: pos + window_size] \\\n",
    "#                         if pos + window_size < len(walk) \\\n",
    "#                         else walk[pos + 1:]\n",
    "\n",
    "#                 context_pairs = [[token, context]\n",
    "#                                  for context in lcontext + rcontext]\n",
    "#                 pairs += context_pairs\n",
    "#         np.random.shuffle(pairs)\n",
    "#         self.pairs = pairs\n",
    "#         return\n",
    "\n",
    "#     def write_pairs(self):\n",
    "#         \"\"\"Write all pairs to files\n",
    "#         Args:\n",
    "#             pairs - the corpus\n",
    "#         Return:\n",
    "#         \"\"\"\n",
    "#         print(\"Writing Generated Pairs to files ...\")\n",
    "#         DATA_DIR = os.getcwd() + \"/corpus/\"\n",
    "#         OUTPUT = DATA_DIR + self._dataset + \"_\" + \\\n",
    "#                  str(self._coverage) + \"_\" + str(self._walk_length) + \".txt\"\n",
    "#         if not os.path.exists(DATA_DIR):\n",
    "#             os.mkdir(DATA_DIR)\n",
    "#         with open(OUTPUT, \"w\") as fout:\n",
    "#             for pair in self.pairs:\n",
    "#                 print(\"{} {}\".format(pair[0], pair[1]), file=fout)\n",
    "#         return\n",
    "\n",
    "#     def down_sample(self):\n",
    "#         \"\"\"Down sampling the training sets\n",
    "        \n",
    "#         1. Remove all the duplicate tuples such as \"A_11 A_11\"\n",
    "#         2. Take log of all tuples as a down sampling\n",
    "#         \"\"\"\n",
    "\n",
    "#         pairs = self.pairs\n",
    "#         pairs = [(pair[0], pair[1])\n",
    "#                  for pair in pairs\n",
    "#                  if pair[0] != pair[1]]\n",
    "#         cnt = Counter(pairs)\n",
    "#         down_cnt = [[pair] * math.ceil(math.log(count))\n",
    "#                     for pair, count in cnt.items()]\n",
    "#         self.pairs = list(itertools.chain(*down_cnt))\n",
    "#         np.random.shuffle(self.pairs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_choice(seq, prob):\n",
    "\n",
    "\n",
    "    p = random.random()\n",
    "    for i in range(len(seq)):\n",
    "        if sum(prob[:i]) < p <= sum(prob[:i+1]):\n",
    "            res=seq[i]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import networkx as nx\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "class MetaPathGenerator:\n",
    "    \"\"\"MetaPathGenerator\n",
    "\n",
    "    Args:\n",
    "        dataset     - the dataset to work on\n",
    "        length      - the length of random walks to be generated\n",
    "        num_walks   - the number of random walks start from each node\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, length=100, coverage=10000):\n",
    "        self._walk_length = length\n",
    "        self._coverage = coverage\n",
    "        self._dataset = dataset\n",
    "        self.G = nx.Graph()\n",
    "\n",
    "        self.walks = []\n",
    "        self.pairs = []\n",
    "\n",
    "        self.initialize()\n",
    "    \n",
    "    def initialize(self):\n",
    "        \"\"\" Initialize Graph\n",
    "\n",
    "        Initialize graph with Uq-Q pairs and Q-Ua pairs.\n",
    "        We use following Uppercase letter\n",
    "\n",
    "        Args:\n",
    "            QR_file - Input file containing Q-R pairs\n",
    "            QA_file - Input file containing Q-A pairs\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        DATA_DIR = os.getcwd() + \"/data/parsed/\" + self._dataset + \"/\"\n",
    "        QR_file = DATA_DIR + \"Q_R.txt\"\n",
    "        QA_file = DATA_DIR + \"Q_A.txt\"\n",
    "        G = self.G\n",
    "\n",
    "        # Read in Uq-Q pairs\n",
    "        with open(QR_file, \"r\") as fin:\n",
    "            lines = fin.readlines()\n",
    "            RQ_edge_list = []\n",
    "            for line in lines:\n",
    "                unit = line.strip().split()\n",
    "                RQ_edge_list.append([\"Q_\" + unit[0],\n",
    "                                     \"R_\" + unit[1]])\n",
    "            G.add_edges_from(RQ_edge_list)\n",
    "        with open(QA_file, \"r\") as fin:\n",
    "            lines = fin.readlines()\n",
    "            QA_edge_list = []\n",
    "            for line in lines:\n",
    "                unit = line.strip().split()\n",
    "                QA_edge_list.append([\"Q_\" + unit[0],\n",
    "                                     \"A_\" + unit[1]])\n",
    "                if int(unit[2])>=0:\n",
    "                    G.add_edge(\"Q_\" + unit[0],\n",
    "                            \"A_\" + unit[1],weight= int(unit[2])+1)\n",
    "                    #votes[unit[1]]=int(unit[2])+1\n",
    "                    #e_expert[]\n",
    "                else:\n",
    "                     G.add_edge(\"Q_\" + unit[0],\n",
    "                            \"A_\" + unit[1],weight = int(unit[2]))\n",
    "            #G.add_edges_from(QA_edge_list,weight=)\n",
    "\n",
    "    def get_nodelist(self, type=None):\n",
    "        \"\"\" Get specific type or all nodes of nodelist in the graph\n",
    "\n",
    "        Args:\n",
    "            type - The entity type of the entity.\n",
    "                   If set as `None`, then all types of nodes would be returned.\n",
    "\n",
    "        Return:\n",
    "            nodelist - the list of node with `type`\n",
    "        \"\"\"\n",
    "        G = self.G\n",
    "\n",
    "        if not G.number_of_edges() or not G.number_of_nodes():\n",
    "            sys.exit(\"Graph should be initialized before get_nodelist()!\")\n",
    "\n",
    "        if not type:\n",
    "            return list(G.nodes)\n",
    "        return [node for node in list(G.nodes)\n",
    "                if node[0] == type]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def generate_metapaths(self, patterns, alpha):\n",
    "        \"\"\" Generate Random Walk\n",
    "\n",
    "        Generating random walk from the Tripartite graph\n",
    "        A candidate pattern pool is:\n",
    "            \"A-Q-R-Q-A\": specifies 2 A's answered a question proposed by a same R\n",
    "            \"A-Q-A\": speficies 2 A' answered a same question\n",
    "\n",
    "        Args:\n",
    "            meta_pattern - the pattern that guides the walk generation\n",
    "            alpha - probability of restart\n",
    "\n",
    "        Return:\n",
    "            walks - a set of generated random walks\n",
    "        \"\"\"\n",
    "        G = self.G\n",
    "        num_walks, walk_len = self._coverage, self._walk_length\n",
    "        rand = random.Random(0)\n",
    "\n",
    "        print(\"Generating Meta-paths ...\")\n",
    "\n",
    "        if not G.number_of_edges() or not G.number_of_nodes():\n",
    "            sys.exit(\"Graph should be initialized before generate_walks()!\")\n",
    "\n",
    "        walks = []\n",
    "\n",
    "        for meta_pattern in patterns:  # Generate by patterns\n",
    "            print(\"\\tNow generating meta-paths from pattern: \\\"{}\\\" ...\"\n",
    "                  .format(meta_pattern))\n",
    "            start_entity_type = meta_pattern[0]\n",
    "            start_node_list = self.get_nodelist(start_entity_type)\n",
    "            for cnt in range(num_walks):  # Iterate the node set for cnt times\n",
    "                print(\"Count={}\".format(cnt))\n",
    "                rand.shuffle(start_node_list)\n",
    "                total = len(start_node_list)                \n",
    "                for ind, start_node in enumerate(start_node_list):\n",
    "                    if ind % 3000 == 0:\n",
    "                        print(\"Finished {:.2f}\".format(ind/total))\n",
    "\n",
    "                    walks.append(\n",
    "                        self.__meta_path_walk(\n",
    "                            start=start_node,\n",
    "                            alpha=alpha,\n",
    "                            pattern=meta_pattern))\n",
    "\n",
    "        print(\"Done!\")\n",
    "        self.walks = walks\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def generate_expertisemetapaths(self, patterns, alpha):\n",
    "        \"\"\" Generate Random Walk\n",
    "\n",
    "        Generating random walk from the Tripartite graph\n",
    "        A candidate pattern pool is:\n",
    "            \"A-Q-R-Q-A\": specifies 2 A's answered a question proposed by a same R\n",
    "            \"A-Q-A\": speficies 2 A' answered a same question\n",
    "\n",
    "        Args:\n",
    "            meta_pattern - the pattern that guides the walk generation\n",
    "            alpha - probability of restart\n",
    "\n",
    "        Return:\n",
    "            walks - a set of generated random walks\n",
    "        \"\"\"\n",
    "        G = self.G\n",
    "        num_walks, walk_len = self._coverage, self._walk_length\n",
    "        rand = random.Random(0)\n",
    "\n",
    "        print(\"Generating Meta-paths ...\")\n",
    "\n",
    "        if not G.number_of_edges() or not G.number_of_nodes():\n",
    "            sys.exit(\"Graph should be initialized before generate_walks()!\")\n",
    "\n",
    "        walks = []\n",
    "\n",
    "        for meta_pattern in patterns:  # Generate by patterns\n",
    "            print(\"\\tNow generating meta-paths from pattern: \\\"{}\\\" ...\"\n",
    "                  .format(meta_pattern))\n",
    "            start_entity_type = meta_pattern[0]\n",
    "            start_node_list = self.get_nodelist(start_entity_type)\n",
    "            for cnt in range(num_walks):  # Iterate the node set for cnt times\n",
    "                print(\"Count={}\".format(cnt))\n",
    "                rand.shuffle(start_node_list)\n",
    "                total = len(start_node_list)                \n",
    "                for ind, start_node in enumerate(start_node_list):\n",
    "                    if ind % 3000 == 0:\n",
    "                        print(\"Finished {:.2f}\".format(ind/total))\n",
    "\n",
    "                    walks.append(\n",
    "                        self.__metaexpertise_path_walk(\n",
    "                            start=start_node,\n",
    "                            alpha=alpha,\n",
    "                            pattern=meta_pattern))\n",
    "\n",
    "        print(\"Done!\")\n",
    "        self.walks = walks\n",
    "        return\n",
    "\n",
    "    def generate_metapaths_2(self):\n",
    "        \"\"\" Generate Random Walk\n",
    "\n",
    "        Generating random walk from the Tripartite graph\n",
    "        Args:\n",
    "            meta_pattern - the pattern that guides the walk generation\n",
    "            alpha - probability of restart\n",
    "\n",
    "        Return:\n",
    "            walks - a set of generated random walks\n",
    "        \"\"\"\n",
    "        G = self.G\n",
    "        num_walks, walk_len = self._coverage, self._walk_length\n",
    "        rand = random.Random(0)\n",
    "\n",
    "        print(\"Generating Meta-paths ...\")\n",
    "\n",
    "        if not G.number_of_edges() or not G.number_of_nodes():\n",
    "            sys.exit(\"Graph should be initialized before generate_walks()!\")\n",
    "\n",
    "        walks = []\n",
    "\n",
    "        print(\"\\tNow generating meta-paths from deepwalk ...\")\n",
    "        start_node_list = self.get_nodelist()\n",
    "        for cnt in range(num_walks):  # Iterate the node set for cnt times\n",
    "            print(\"Count={}\".format(cnt))\n",
    "            rand.shuffle(start_node_list)\n",
    "            total = len(start_node_list)\n",
    "            for ind, start_node in enumerate(start_node_list):\n",
    "                if ind % 3000 == 0:\n",
    "                    print(\"Finished {:.2f}\".format(ind/total))\n",
    "                walks.append(\n",
    "                    self.__random_walk(start=start_node))\n",
    "\n",
    "        print(\"Done!\")\n",
    "        self.walks = walks\n",
    "        return\n",
    "\n",
    "    def __random_walk(self, start=None):\n",
    "        \"\"\"Single Random Walk Generator\n",
    "\n",
    "        Args:\n",
    "            rand - an random object to generate random numbers\n",
    "            start - starting node\n",
    "\n",
    "        Return:\n",
    "            walk - the single walk generated\n",
    "        \"\"\"\n",
    "        G = self.G\n",
    "        rand = random.Random()\n",
    "        walk = [start]\n",
    "        cur_node = start\n",
    "        while len(walk) <= self._walk_length:\n",
    "            possible_next_nodes = [neighbor\n",
    "                                   for neighbor in G.neighbors(cur_node)]\n",
    "            next_node = rand.choice(possible_next_nodes)\n",
    "            walk.append(next_node)\n",
    "            cur_node = next_node\n",
    "\n",
    "        return \" \".join(walk)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def __meta_path_walk(self, start=None, alpha=0.0, pattern=None):\n",
    "        \"\"\"Single Walk Generator\n",
    "\n",
    "        Generating a single random walk that follows a meta path of `pattern`\n",
    "\n",
    "        Args:\n",
    "            rand - an random object to generate random numbers\n",
    "            start - starting node\n",
    "            alpha - probability of restarts\n",
    "            pattern - (string) the pattern according to which to generate walks\n",
    "            walk_len - (int) the length of the generated walk\n",
    "\n",
    "        Return:\n",
    "            walk - the single walk generated\n",
    "\n",
    "        \"\"\"\n",
    "        def type_of(node_id):\n",
    "            return node_id[0]\n",
    "\n",
    "        rand = random.Random()\n",
    "        # Checking pattern is correctly initialized\n",
    "        if not pattern:\n",
    "            sys.exit(\"Pattern is not specified when generating meta-path walk\")\n",
    "\n",
    "        G = self.G\n",
    "        n, pat_ind = 1, 1\n",
    "\n",
    "        walk = [start]\n",
    "\n",
    "        cur_node = start\n",
    "\n",
    "        # Generating meta-paths\n",
    "        while len(walk) <= self._walk_length or pat_ind != len(pattern):\n",
    "\n",
    "            # Updating the pattern index\n",
    "            pat_ind = pat_ind if pat_ind != len(pattern) else 1\n",
    "\n",
    "            # Decide whether to restart\n",
    "            if rand.random() >= alpha:\n",
    "                # Find all possible next neighbors\n",
    "                possible_next_node = [neighbor\n",
    "                                      for neighbor in G.neighbors(cur_node)\n",
    "                                      if type_of(neighbor) == pattern[pat_ind]]\n",
    "                # Random choose next node\n",
    "                \n",
    "                next_node = rand.choice(possible_next_node)\n",
    "            else:\n",
    "                next_node = walk[0]\n",
    "\n",
    "            walk.append(next_node)\n",
    "            cur_node = next_node\n",
    "            pat_ind += 1\n",
    "\n",
    "        return \" \".join(walk)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def __metaexpertise_path_walk(self, start=None, alpha=0.0, pattern=None):\n",
    "        \"\"\"Single Walk Generator\n",
    "\n",
    "        Generating a single random walk that follows a meta path of `pattern`\n",
    "\n",
    "        Args:\n",
    "            rand - an random object to generate random numbers\n",
    "            start - starting node\n",
    "            alpha - probability of restarts\n",
    "            pattern - (string) the pattern according to which to generate walks\n",
    "            walk_len - (int) the length of the generated walk\n",
    "\n",
    "        Return:\n",
    "            walk - the single walk generated\n",
    "\n",
    "        \"\"\"\n",
    "        def type_of(node_id):\n",
    "            return node_id[0]\n",
    "\n",
    "        rand = random.Random()\n",
    "        # Checking pattern is correctly initialized\n",
    "        if not pattern:\n",
    "            sys.exit(\"Pattern is not specified when generating meta-path walk\")\n",
    "\n",
    "        G = self.G\n",
    "        n, pat_ind = 1, 1\n",
    "\n",
    "        walk = [start]\n",
    "\n",
    "        cur_node = start\n",
    "\n",
    "        # Generating meta-paths\n",
    "        while len(walk) <= self._walk_length or pat_ind != len(pattern):\n",
    "\n",
    "            # Updating the pattern index\n",
    "            pat_ind = pat_ind if pat_ind != len(pattern) else 1\n",
    "\n",
    "            # Decide whether to restart\n",
    "            if rand.random() >= alpha:\n",
    "                # Find all possible next neighbors\n",
    "                #print(\"1\",cur_node)\n",
    "                possible_next_node = [neighbor\n",
    "                                      for neighbor in G.neighbors(cur_node)\n",
    "                                      if type_of(neighbor) == pattern[pat_ind]]\n",
    "                \n",
    "                # Random choose next node\n",
    "                if cur_node[0]==\"Q\" and pattern[pat_ind]==\"A\":\n",
    "                    nextnodes=list()\n",
    "                    pro=list()\n",
    "                    s=list()\n",
    "                    for i in possible_next_node:\n",
    "                        s.append(G[cur_node][i]['weight'])\n",
    "                    #print(\"sssss\",s)\n",
    "                    if max(s)>0:\n",
    "                        #print(\"sssssssssss\",s)\n",
    "                        for i in possible_next_node:\n",
    "\n",
    "\n",
    "                            if G[cur_node][i]['weight']>0:\n",
    "                                nextnodes.append(i)\n",
    "                                pro.append(G[cur_node][i]['weight'])\n",
    "\n",
    "                        pro=np.array(np.array(pro)/sum(pro))\n",
    "\n",
    "                        next_node = random_choice(nextnodes,pro)\n",
    "                    else:\n",
    "                        next_node = rand.choice(possible_next_node)\n",
    "                            \n",
    "                #else:\n",
    "                #    next_node = rand.choice(possible_next_node)\n",
    "                    \n",
    "                    \n",
    "                elif cur_node[0]==\"A\" and pattern[pat_ind]==\"Q\":\n",
    "                    nextnodes=list()\n",
    "                    pro=list()\n",
    "                    s=list()\n",
    "                    \n",
    "                    for i in possible_next_node:\n",
    "                        s.append(G[cur_node][i]['weight'])\n",
    "                    if max(s)>0:\n",
    "\n",
    "                        for i in possible_next_node:\n",
    "\n",
    "\n",
    "                            if G[cur_node][i]['weight']>0:\n",
    "                                nextnodes.append(i)\n",
    "                                pro.append(G[cur_node][i]['weight'])\n",
    "\n",
    "                        pro=np.array(np.array(pro)/sum(pro))\n",
    "\n",
    "                        next_node = random_choice(nextnodes,pro)\n",
    "                    else:\n",
    "                        next_node = rand.choice(possible_next_node)\n",
    "                            \n",
    "                else:\n",
    "                    next_node = rand.choice(possible_next_node)      \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            else:\n",
    "                next_node = walk[0]\n",
    "\n",
    "            walk.append(next_node)\n",
    "            cur_node = next_node\n",
    "            pat_ind += 1\n",
    "\n",
    "        return \" \".join(walk)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def random_choice(self,seq, prob):\n",
    "\n",
    "       \n",
    "        p = random.random()\n",
    "        for i in range(len(seq)):\n",
    "            if sum(prob[:i]) < p <= sum(prob[:i+1]):\n",
    "                res=seq[i]\n",
    "        return res\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def write_metapaths(self):\n",
    "        \"\"\"Write Metapaths to files\n",
    "\n",
    "        Args:\n",
    "            walks - The walks generated by `generate_walks`\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"Writing Generated Meta-paths to files ...\", end=\" \")\n",
    "\n",
    "        DATA_DIR = os.getcwd() + \"/metapath/\"\n",
    "        OUTPUT = DATA_DIR + self._dataset + \"_\" \\\n",
    "                 + str(self._coverage) + \"_\" + str(self._walk_length) + \".txt\"\n",
    "        if not os.path.exists(DATA_DIR):\n",
    "            os.mkdir(DATA_DIR)\n",
    "        with open(OUTPUT, \"w\") as fout:\n",
    "            for walk in self.walks:\n",
    "                print(\"{}\".format(walk), file=fout)\n",
    "\n",
    "        print(\"Done!\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def write_expertmetapaths(self):\n",
    "        \"\"\"Write Metapaths to files\n",
    "\n",
    "        Args:\n",
    "            walks - The walks generated by `generate_walks`\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"Writing Generated Meta-paths to files ...\", end=\" \")\n",
    "\n",
    "        DATA_DIR = os.getcwd() + \"/metapath/\"\n",
    "        OUTPUT = DATA_DIR + self._dataset + \"_\" \\\n",
    "                 + str(self._coverage) + \"_\" + str(self._walk_length) + \"e\"+\".txt\"\n",
    "        if not os.path.exists(DATA_DIR):\n",
    "            os.mkdir(DATA_DIR)\n",
    "        with open(OUTPUT, \"w\") as fout:\n",
    "            for walk in self.walks:\n",
    "                print(\"{}\".format(walk), file=fout)\n",
    "\n",
    "        print(\"Done!\")\n",
    "\n",
    "\n",
    "    def path_to_pairs(self, window_size):\n",
    "        \"\"\"Convert all metapaths to pairs of nodes\n",
    "\n",
    "        Args:\n",
    "            walks - all the walks to be translated\n",
    "            window_size - the sliding window size\n",
    "        Return:\n",
    "            pairs - the *shuffled* pair corpus of the dataset\n",
    "        \"\"\"\n",
    "        pairs = []\n",
    "        if not self.walks:\n",
    "            sys.exit(\"Walks haven't been created.\")\n",
    "        for walk in self.walks:\n",
    "            walk = walk.strip().split(' ')\n",
    "            for pos, token in enumerate(walk):\n",
    "                lcontext, rcontext = [], []\n",
    "                lcontext = walk[pos - window_size: pos] \\\n",
    "                    if pos - window_size >= 0 \\\n",
    "                    else walk[:pos]\n",
    "\n",
    "                if pos + 1 < len(walk):\n",
    "                    rcontext = walk[pos + 1: pos + window_size] \\\n",
    "                        if pos + window_size < len(walk) \\\n",
    "                        else walk[pos + 1:]\n",
    "\n",
    "                context_pairs = [[token, context]\n",
    "                                 for context in lcontext + rcontext]\n",
    "                pairs += context_pairs\n",
    "        np.random.shuffle(pairs)\n",
    "        self.pairs = pairs\n",
    "        return\n",
    "\n",
    "    def write_pairs(self):\n",
    "        \"\"\"Write all pairs to files\n",
    "        Args:\n",
    "            pairs - the corpus\n",
    "        Return:\n",
    "        \"\"\"\n",
    "        print(\"Writing Generated Pairs to files ...\")\n",
    "        DATA_DIR = os.getcwd() + \"/corpus/\"\n",
    "        OUTPUT = DATA_DIR + self._dataset + \"_\" + \\\n",
    "                 str(self._coverage) + \"_\" + str(self._walk_length) + \".txt\"\n",
    "        if not os.path.exists(DATA_DIR):\n",
    "            os.mkdir(DATA_DIR)\n",
    "        with open(OUTPUT, \"w\") as fout:\n",
    "            for pair in self.pairs:\n",
    "                print(\"{} {}\".format(pair[0], pair[1]), file=fout)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def write_epairs(self):\n",
    "        \"\"\"Write all pairs to files\n",
    "        Args:\n",
    "            pairs - the corpus\n",
    "        Return:\n",
    "        \"\"\"\n",
    "        print(\"Writing Generated Pairs to files ...\")\n",
    "        DATA_DIR = os.getcwd() + \"/corpus/\"\n",
    "        OUTPUT = DATA_DIR + self._dataset + \"_\" + \\\n",
    "                 str(self._coverage) + \"_\" + str(self._walk_length) + \"e\"+\".txt\"\n",
    "        if not os.path.exists(DATA_DIR):\n",
    "            os.mkdir(DATA_DIR)\n",
    "        with open(OUTPUT, \"w\") as fout:\n",
    "            for pair in self.pairs:\n",
    "                print(\"{} {}\".format(pair[0], pair[1]), file=fout)\n",
    "        return\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    def down_sample(self):\n",
    "        \"\"\"Down sampling the training sets\n",
    "        \n",
    "        1. Remove all the duplicate tuples such as \"A_11 A_11\"\n",
    "        2. Take log of all tuples as a down sampling\n",
    "        \"\"\"\n",
    "\n",
    "        pairs = self.pairs\n",
    "        pairs = [(pair[0], pair[1])\n",
    "                 for pair in pairs\n",
    "                 if pair[0] != pair[1]]\n",
    "        cnt = Counter(pairs)\n",
    "        down_cnt = [[pair] * math.ceil(math.log(count))\n",
    "                    for pair, count in cnt.items()]\n",
    "        self.pairs = list(itertools.chain(*down_cnt))\n",
    "        np.random.shuffle(self.pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Meta-paths ...\n",
      "\tNow generating meta-paths from pattern: \"RQAQR\" ...\n",
      "Count=0\n",
      "Finished 0.00\n",
      "Finished 0.66\n",
      "Count=1\n",
      "Finished 0.00\n",
      "Finished 0.66\n",
      "Count=2\n",
      "Finished 0.00\n",
      "Finished 0.66\n",
      "Count=3\n",
      "Finished 0.00\n",
      "Finished 0.66\n",
      "Count=4\n",
      "Finished 0.00\n",
      "Finished 0.66\n",
      "Done!\n",
      "Writing Generated Meta-paths to files ... Done!\n",
      "Writing Generated Pairs to files ...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    dataset='Biology'\n",
    "    gw = MetaPathGenerator(length=5, coverage=5, dataset=dataset)\n",
    "\n",
    "    # Uncomment the first line for metapath-based\n",
    "    gw.generate_metapaths(patterns=[\"RQAQR\"], alpha=0)\n",
    "    #gw.generate_metapaths_2()\n",
    "    gw.path_to_pairs(window_size=5)\n",
    "    gw.down_sample()\n",
    "    gw.write_metapaths()\n",
    "    gw.write_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Meta-paths ...\n",
      "\tNow generating meta-paths from pattern: \"RQAQR\" ...\n",
      "Count=0\n",
      "Finished 0.00\n",
      "Finished 0.66\n",
      "Count=1\n",
      "Finished 0.00\n",
      "Finished 0.66\n",
      "Count=2\n",
      "Finished 0.00\n",
      "Finished 0.66\n",
      "Count=3\n",
      "Finished 0.00\n",
      "Finished 0.66\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    dataset='Biology'\n",
    "    gw = MetaPathGenerator(length=5, coverage=5, dataset=dataset)\n",
    "\n",
    "    # Uncomment the first line for metapath-based\n",
    "    gw.generate_expertisemetapaths(patterns=[\"RQAQR\"], alpha=0)\n",
    "    #gw.generate_metapaths_2()\n",
    "    gw.path_to_pairs(window_size=5)\n",
    "    gw.down_sample()\n",
    "    gw.write_expertmetapaths()\n",
    "    gw.write_epairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data_loader ...\n",
      "\tLoading dataset .../home/dutir/qianlingfei/network-embedding-er/corpus/Biology_5_5.txt\n",
      "\tCounting dataset ...\n",
      "\tInitializing sample table ...\n",
      "\tLoading word2vec model ...\n",
      "\tLoading questions text ...\n",
      "\tCreating user-index mapping ...\n",
      "data_loader: user_count 6342\n",
      "\tLoading rqa ...\n",
      "\tCreating qid embeddings map ...\n",
      "\tLoading test sets ...\n",
      "Done - Data Loader!\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoader(dataset=\"Biology\"\n",
    "                     , ID=id\n",
    "                     , include_content=0\n",
    "                     , coverage=5\n",
    "                     , length=5\n",
    "                     , answer_sample_ratio=3\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0.3181818181818182\n"
     ]
    }
   ],
   "source": [
    "u, v,upos, vpos, npos, aqr, accqr,point_wise, point=dl.get_train_batch(\n",
    "                        batch_size=100,\n",
    "                        neg_ratio=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 2.55555556, 1.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "       0.16666667, 1.        , 0.5       , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 1.        , 1.        , 2.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 1.        , 1.        , 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  129,    68,   753],\n",
       "       [  129,   107,   753],\n",
       "       [  129,    68,   753],\n",
       "       [  129,   752,   753],\n",
       "       [  129, 19454,   753],\n",
       "       [  129,  1202,   753],\n",
       "       [  129,  3059,   753],\n",
       "       [  129, 35570,   753],\n",
       "       [  129, 16917,   753],\n",
       "       [ 4108, 14849, 19692],\n",
       "       [ 4108, 11829, 19692],\n",
       "       [ 4108, 14849, 19692],\n",
       "       [ 4108, 23053, 19692],\n",
       "       [ 4108, 13266, 19692],\n",
       "       [ 4108,  3444, 19692],\n",
       "       [ 4108, 29777, 19692],\n",
       "       [ 4108, 30418, 19692],\n",
       "       [ 4108,  8598, 19692],\n",
       "       [ 4108, 35811, 19692],\n",
       "       [ 4108, 32974, 19692],\n",
       "       [ 4108, 42293, 19692],\n",
       "       [ 4108,  9054, 19692],\n",
       "       [  389,  3632,  3279],\n",
       "       [  389,  3632,  3279],\n",
       "       [  389,  1305,  3279],\n",
       "       [  389,  3536,  3279],\n",
       "       [  389, 41761,  3279],\n",
       "       [  389,  9358,  3279],\n",
       "       [  389, 30418,  3279],\n",
       "       [  389, 28096,  3279],\n",
       "       [  389, 24565,  3279],\n",
       "       [  491,   107,  1018],\n",
       "       [  491,   107,  1018],\n",
       "       [  491, 33710,  1018],\n",
       "       [  491, 43183,  1018],\n",
       "       [  491, 14916,  1018]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Meta-paths ...\n",
      "\tNow generating meta-paths from pattern: \"RQAQR\" ...\n",
      "Count=0\n",
      "Finished 0.00\n",
      "Finished 0.66\n",
      "Count=1\n",
      "Finished 0.00\n",
      "Finished 0.66\n",
      "Count=2\n",
      "Finished 0.00\n",
      "Finished 0.66\n",
      "Count=3\n",
      "Finished 0.00\n",
      "Finished 0.66\n",
      "Count=4\n",
      "Finished 0.00\n",
      "Finished 0.66\n",
      "Done!\n",
      "Writing Generated Meta-paths to files ... Done!\n",
      "Writing Generated Pairs to files ...\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     dataset='Biology'\n",
    "#     gw = MetaPathGenerator(length=5, coverage=5, dataset=dataset)\n",
    "\n",
    "#     # Uncomment the first line for metapath-based\n",
    "#     gw.generate_expertisemetapaths(patterns=[\"RQAQR\"], alpha=0)\n",
    "#     #gw.generate_metapaths_2()\n",
    "#     gw.path_to_pairs(window_size=5)\n",
    "#     gw.down_sample()\n",
    "#     gw.write_expertmetapaths()\n",
    "#     gw.write_epairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     dataset='Biology'\n",
    "#     gw = MetaPathGenerator(length=5, coverage=5, dataset=dataset)\n",
    "\n",
    "#     # Uncomment the first line for metapath-based\n",
    "#     #gw.generate_metapaths(patterns=[\"RQAQR\"], alpha=0)\n",
    "#     gw.generate_metapaths_2()\n",
    "#     gw.path_to_pairs(window_size=5)\n",
    "#     gw.down_sample()\n",
    "#     gw.write_expertmetapaths()\n",
    "#     gw.write_epairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "if max([-1,-2])>0:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw = MetaPathGenerator(length=5, coverage=5, dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.4, 0.6, 0.6])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([12,3,3])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Meta-paths ...\n",
      "\tNow generating meta-paths from pattern: \"QSASQ\" ...\n",
      "Count=0\n",
      "Finished 0.00\n",
      "Count=1\n",
      "Finished 0.00\n",
      "Count=2\n",
      "Finished 0.00\n",
      "Count=3\n",
      "Finished 0.00\n",
      "Count=4\n",
      "Finished 0.00\n",
      "Done!\n",
      "Writing Generated Meta-paths to files ... Done!\n",
      "Writing Generated Pairs to files ...\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     dataset='English'\n",
    "#     gw = MetaPathGenerator(length=5, coverage=5, dataset=dataset)\n",
    "\n",
    "#     # Uncomment the first line for metapath-based\n",
    "#     gw.generate_metapaths(patterns=[\"QSASQ\"], alpha=0)\n",
    "#     #gw.generate_metapaths_2()\n",
    "#     gw.path_to_pairs(window_size=5)\n",
    "#     gw.down_sample()\n",
    "#     gw.write_metapaths()\n",
    "#     gw.write_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Meta-paths ...\n",
      "\tNow generating meta-paths from pattern: \"SQRQS\" ...\n",
      "Count=0\n",
      "Finished 0.00\n",
      "Count=1\n",
      "Finished 0.00\n",
      "Count=2\n",
      "Finished 0.00\n",
      "Count=3\n",
      "Finished 0.00\n",
      "Count=4\n",
      "Finished 0.00\n",
      "Done!\n",
      "Writing Generated Meta-paths to files ... Done!\n",
      "Writing Generated Pairs to files ...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    dataset='English'\n",
    "    gw = MetaPathGenerator(length=5, coverage=5, dataset=dataset)\n",
    "\n",
    "    # Uncomment the first line for metapath-based\n",
    "    gw.generate_metapaths(patterns=[\"SQRQS\"], alpha=0)\n",
    "    #gw.generate_metapaths_2()\n",
    "    gw.path_to_pairs(window_size=5)\n",
    "    gw.down_sample()\n",
    "    gw.write_metapaths()\n",
    "    gw.write_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "window_size=5\n",
    "if not gw.walks:\n",
    "    sys.exit(\"Walks haven't been created.\")\n",
    "for walk in gw.walks:\n",
    "    walk = walk.strip().split(' ')\n",
    "    for pos, token in enumerate(walk):\n",
    "        lcontext, rcontext = [], []\n",
    "        lcontext = walk[pos - window_size: pos] \\\n",
    "            if pos - window_size >= 0 \\\n",
    "            else walk[:pos]\n",
    "\n",
    "        if pos + 1 < len(walk):\n",
    "            rcontext = walk[pos + 1: pos + window_size] \\\n",
    "                if pos + window_size < len(walk) \\\n",
    "                else walk[pos + 1:]\n",
    "\n",
    "        context_pairs = [[token, context]\n",
    "                         for context in lcontext + rcontext]\n",
    "        pairs += context_pairs\n",
    "#np.random.shuffle(pairs)\n",
    "pairs = pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A_184706', 'Q_9371'],\n",
       " ['A_184706', 'R_61075'],\n",
       " ['A_184706', 'Q_9371'],\n",
       " ['A_184706', 'S_9374'],\n",
       " ['Q_9371', 'A_184706'],\n",
       " ['Q_9371', 'R_61075'],\n",
       " ['Q_9371', 'Q_9371'],\n",
       " ['Q_9371', 'S_9374'],\n",
       " ['Q_9371', 'Q_9371'],\n",
       " ['R_61075', 'A_184706'],\n",
       " ['R_61075', 'Q_9371'],\n",
       " ['R_61075', 'Q_9371'],\n",
       " ['R_61075', 'S_9374'],\n",
       " ['R_61075', 'Q_9371'],\n",
       " ['R_61075', 'R_61075'],\n",
       " ['Q_9371', 'A_184706'],\n",
       " ['Q_9371', 'Q_9371'],\n",
       " ['Q_9371', 'R_61075'],\n",
       " ['Q_9371', 'S_9374'],\n",
       " ['Q_9371', 'Q_9371'],\n",
       " ['Q_9371', 'R_61075'],\n",
       " ['Q_9371', 'Q_9386'],\n",
       " ['S_9374', 'A_184706'],\n",
       " ['S_9374', 'Q_9371'],\n",
       " ['S_9374', 'R_61075'],\n",
       " ['S_9374', 'Q_9371'],\n",
       " ['S_9374', 'Q_9371'],\n",
       " ['S_9374', 'R_61075'],\n",
       " ['S_9374', 'Q_9386'],\n",
       " ['S_9374', 'S_9387'],\n",
       " ['Q_9371', 'A_184706'],\n",
       " ['Q_9371', 'Q_9371'],\n",
       " ['Q_9371', 'R_61075'],\n",
       " ['Q_9371', 'Q_9371'],\n",
       " ['Q_9371', 'S_9374'],\n",
       " ['Q_9371', 'R_61075'],\n",
       " ['Q_9371', 'Q_9386'],\n",
       " ['Q_9371', 'S_9387'],\n",
       " ['R_61075', 'Q_9371'],\n",
       " ['R_61075', 'R_61075'],\n",
       " ['R_61075', 'Q_9371'],\n",
       " ['R_61075', 'S_9374'],\n",
       " ['R_61075', 'Q_9371'],\n",
       " ['R_61075', 'Q_9386'],\n",
       " ['R_61075', 'S_9387'],\n",
       " ['Q_9386', 'R_61075'],\n",
       " ['Q_9386', 'Q_9371'],\n",
       " ['Q_9386', 'S_9374'],\n",
       " ['Q_9386', 'Q_9371'],\n",
       " ['Q_9386', 'R_61075'],\n",
       " ['Q_9386', 'S_9387'],\n",
       " ['S_9387', 'Q_9371'],\n",
       " ['S_9387', 'S_9374'],\n",
       " ['S_9387', 'Q_9371'],\n",
       " ['S_9387', 'R_61075'],\n",
       " ['S_9387', 'Q_9386'],\n",
       " ['A_36727', 'Q_6636'],\n",
       " ['A_36727', 'R_105642'],\n",
       " ['A_36727', 'Q_6636'],\n",
       " ['A_36727', 'S_6639'],\n",
       " ['Q_6636', 'A_36727'],\n",
       " ['Q_6636', 'R_105642'],\n",
       " ['Q_6636', 'Q_6636'],\n",
       " ['Q_6636', 'S_6639'],\n",
       " ['Q_6636', 'Q_6636'],\n",
       " ['R_105642', 'A_36727'],\n",
       " ['R_105642', 'Q_6636'],\n",
       " ['R_105642', 'Q_6636'],\n",
       " ['R_105642', 'S_6639'],\n",
       " ['R_105642', 'Q_6636'],\n",
       " ['R_105642', 'R_105642'],\n",
       " ['Q_6636', 'A_36727'],\n",
       " ['Q_6636', 'Q_6636'],\n",
       " ['Q_6636', 'R_105642'],\n",
       " ['Q_6636', 'S_6639'],\n",
       " ['Q_6636', 'Q_6636'],\n",
       " ['Q_6636', 'R_105642'],\n",
       " ['Q_6636', 'Q_6636'],\n",
       " ['S_6639', 'A_36727'],\n",
       " ['S_6639', 'Q_6636'],\n",
       " ['S_6639', 'R_105642'],\n",
       " ['S_6639', 'Q_6636'],\n",
       " ['S_6639', 'Q_6636'],\n",
       " ['S_6639', 'R_105642'],\n",
       " ['S_6639', 'Q_6636'],\n",
       " ['S_6639', 'S_6671'],\n",
       " ['Q_6636', 'A_36727'],\n",
       " ['Q_6636', 'Q_6636'],\n",
       " ['Q_6636', 'R_105642'],\n",
       " ['Q_6636', 'Q_6636'],\n",
       " ['Q_6636', 'S_6639'],\n",
       " ['Q_6636', 'R_105642'],\n",
       " ['Q_6636', 'Q_6636'],\n",
       " ['Q_6636', 'S_6671'],\n",
       " ['R_105642', 'Q_6636'],\n",
       " ['R_105642', 'R_105642'],\n",
       " ['R_105642', 'Q_6636'],\n",
       " ['R_105642', 'S_6639'],\n",
       " ['R_105642', 'Q_6636'],\n",
       " ['R_105642', 'Q_6636'],\n",
       " ['R_105642', 'S_6671'],\n",
       " ['Q_6636', 'R_105642'],\n",
       " ['Q_6636', 'Q_6636'],\n",
       " ['Q_6636', 'S_6639'],\n",
       " ['Q_6636', 'Q_6636'],\n",
       " ['Q_6636', 'R_105642'],\n",
       " ['Q_6636', 'S_6671'],\n",
       " ['S_6671', 'Q_6636'],\n",
       " ['S_6671', 'S_6639'],\n",
       " ['S_6671', 'Q_6636'],\n",
       " ['S_6671', 'R_105642'],\n",
       " ['S_6671', 'Q_6636'],\n",
       " ['A_18696', 'Q_7193'],\n",
       " ['A_18696', 'R_140931'],\n",
       " ['A_18696', 'Q_7193'],\n",
       " ['A_18696', 'S_7195'],\n",
       " ['Q_7193', 'A_18696'],\n",
       " ['Q_7193', 'R_140931'],\n",
       " ['Q_7193', 'Q_7193'],\n",
       " ['Q_7193', 'S_7195'],\n",
       " ['Q_7193', 'Q_7193'],\n",
       " ['R_140931', 'A_18696'],\n",
       " ['R_140931', 'Q_7193'],\n",
       " ['R_140931', 'Q_7193'],\n",
       " ['R_140931', 'S_7195'],\n",
       " ['R_140931', 'Q_7193'],\n",
       " ['R_140931', 'R_140931'],\n",
       " ['Q_7193', 'A_18696'],\n",
       " ['Q_7193', 'Q_7193'],\n",
       " ['Q_7193', 'R_140931'],\n",
       " ['Q_7193', 'S_7195'],\n",
       " ['Q_7193', 'Q_7193'],\n",
       " ['Q_7193', 'R_140931'],\n",
       " ['Q_7193', 'Q_7193'],\n",
       " ['S_7195', 'A_18696'],\n",
       " ['S_7195', 'Q_7193'],\n",
       " ['S_7195', 'R_140931'],\n",
       " ['S_7195', 'Q_7193'],\n",
       " ['S_7195', 'Q_7193'],\n",
       " ['S_7195', 'R_140931'],\n",
       " ['S_7195', 'Q_7193'],\n",
       " ['S_7195', 'S_7195'],\n",
       " ['Q_7193', 'A_18696'],\n",
       " ['Q_7193', 'Q_7193'],\n",
       " ['Q_7193', 'R_140931'],\n",
       " ['Q_7193', 'Q_7193'],\n",
       " ['Q_7193', 'S_7195'],\n",
       " ['Q_7193', 'R_140931'],\n",
       " ['Q_7193', 'Q_7193'],\n",
       " ['Q_7193', 'S_7195'],\n",
       " ['R_140931', 'Q_7193'],\n",
       " ['R_140931', 'R_140931'],\n",
       " ['R_140931', 'Q_7193'],\n",
       " ['R_140931', 'S_7195'],\n",
       " ['R_140931', 'Q_7193'],\n",
       " ['R_140931', 'Q_7193'],\n",
       " ['R_140931', 'S_7195'],\n",
       " ['Q_7193', 'R_140931'],\n",
       " ['Q_7193', 'Q_7193'],\n",
       " ['Q_7193', 'S_7195'],\n",
       " ['Q_7193', 'Q_7193'],\n",
       " ['Q_7193', 'R_140931'],\n",
       " ['Q_7193', 'S_7195'],\n",
       " ['S_7195', 'Q_7193'],\n",
       " ['S_7195', 'S_7195'],\n",
       " ['S_7195', 'Q_7193'],\n",
       " ['S_7195', 'R_140931'],\n",
       " ['S_7195', 'Q_7193'],\n",
       " ['A_202177', 'Q_10836'],\n",
       " ['A_202177', 'R_258304'],\n",
       " ['A_202177', 'Q_10836'],\n",
       " ['A_202177', 'S_10837'],\n",
       " ['Q_10836', 'A_202177'],\n",
       " ['Q_10836', 'R_258304'],\n",
       " ['Q_10836', 'Q_10836'],\n",
       " ['Q_10836', 'S_10837'],\n",
       " ['Q_10836', 'Q_10836'],\n",
       " ['R_258304', 'A_202177'],\n",
       " ['R_258304', 'Q_10836'],\n",
       " ['R_258304', 'Q_10836'],\n",
       " ['R_258304', 'S_10837'],\n",
       " ['R_258304', 'Q_10836'],\n",
       " ['R_258304', 'R_258304'],\n",
       " ['Q_10836', 'A_202177'],\n",
       " ['Q_10836', 'Q_10836'],\n",
       " ['Q_10836', 'R_258304'],\n",
       " ['Q_10836', 'S_10837'],\n",
       " ['Q_10836', 'Q_10836'],\n",
       " ['Q_10836', 'R_258304'],\n",
       " ['Q_10836', 'Q_10857'],\n",
       " ['S_10837', 'A_202177'],\n",
       " ['S_10837', 'Q_10836'],\n",
       " ['S_10837', 'R_258304'],\n",
       " ['S_10837', 'Q_10836'],\n",
       " ['S_10837', 'Q_10836'],\n",
       " ['S_10837', 'R_258304'],\n",
       " ['S_10837', 'Q_10857'],\n",
       " ['S_10837', 'S_10860'],\n",
       " ['Q_10836', 'A_202177'],\n",
       " ['Q_10836', 'Q_10836'],\n",
       " ['Q_10836', 'R_258304'],\n",
       " ['Q_10836', 'Q_10836'],\n",
       " ['Q_10836', 'S_10837'],\n",
       " ['Q_10836', 'R_258304'],\n",
       " ['Q_10836', 'Q_10857'],\n",
       " ['Q_10836', 'S_10860'],\n",
       " ['R_258304', 'Q_10836'],\n",
       " ['R_258304', 'R_258304'],\n",
       " ['R_258304', 'Q_10836'],\n",
       " ['R_258304', 'S_10837'],\n",
       " ['R_258304', 'Q_10836'],\n",
       " ['R_258304', 'Q_10857'],\n",
       " ['R_258304', 'S_10860'],\n",
       " ['Q_10857', 'R_258304'],\n",
       " ['Q_10857', 'Q_10836'],\n",
       " ['Q_10857', 'S_10837'],\n",
       " ['Q_10857', 'Q_10836'],\n",
       " ['Q_10857', 'R_258304'],\n",
       " ['Q_10857', 'S_10860'],\n",
       " ['S_10860', 'Q_10836'],\n",
       " ['S_10860', 'S_10837'],\n",
       " ['S_10860', 'Q_10836'],\n",
       " ['S_10860', 'R_258304'],\n",
       " ['S_10860', 'Q_10857'],\n",
       " ['A_96401', 'Q_7328'],\n",
       " ['A_96401', 'R_129806'],\n",
       " ['A_96401', 'Q_7328'],\n",
       " ['A_96401', 'S_7366'],\n",
       " ['Q_7328', 'A_96401'],\n",
       " ['Q_7328', 'R_129806'],\n",
       " ['Q_7328', 'Q_7328'],\n",
       " ['Q_7328', 'S_7366'],\n",
       " ['Q_7328', 'Q_7328'],\n",
       " ['R_129806', 'A_96401'],\n",
       " ['R_129806', 'Q_7328'],\n",
       " ['R_129806', 'Q_7328'],\n",
       " ['R_129806', 'S_7366'],\n",
       " ['R_129806', 'Q_7328'],\n",
       " ['R_129806', 'R_129806'],\n",
       " ['Q_7328', 'A_96401'],\n",
       " ['Q_7328', 'Q_7328'],\n",
       " ['Q_7328', 'R_129806'],\n",
       " ['Q_7328', 'S_7366'],\n",
       " ['Q_7328', 'Q_7328'],\n",
       " ['Q_7328', 'R_129806'],\n",
       " ['Q_7328', 'Q_7538'],\n",
       " ['S_7366', 'A_96401'],\n",
       " ['S_7366', 'Q_7328'],\n",
       " ['S_7366', 'R_129806'],\n",
       " ['S_7366', 'Q_7328'],\n",
       " ['S_7366', 'Q_7328'],\n",
       " ['S_7366', 'R_129806'],\n",
       " ['S_7366', 'Q_7538'],\n",
       " ['S_7366', 'S_7539'],\n",
       " ['Q_7328', 'A_96401'],\n",
       " ['Q_7328', 'Q_7328'],\n",
       " ['Q_7328', 'R_129806'],\n",
       " ['Q_7328', 'Q_7328'],\n",
       " ['Q_7328', 'S_7366'],\n",
       " ['Q_7328', 'R_129806'],\n",
       " ['Q_7328', 'Q_7538'],\n",
       " ['Q_7328', 'S_7539'],\n",
       " ['R_129806', 'Q_7328'],\n",
       " ['R_129806', 'R_129806'],\n",
       " ['R_129806', 'Q_7328'],\n",
       " ['R_129806', 'S_7366'],\n",
       " ['R_129806', 'Q_7328'],\n",
       " ['R_129806', 'Q_7538'],\n",
       " ['R_129806', 'S_7539'],\n",
       " ['Q_7538', 'R_129806'],\n",
       " ['Q_7538', 'Q_7328'],\n",
       " ['Q_7538', 'S_7366'],\n",
       " ['Q_7538', 'Q_7328'],\n",
       " ['Q_7538', 'R_129806'],\n",
       " ['Q_7538', 'S_7539'],\n",
       " ['S_7539', 'Q_7328'],\n",
       " ['S_7539', 'S_7366'],\n",
       " ['S_7539', 'Q_7328'],\n",
       " ['S_7539', 'R_129806'],\n",
       " ['S_7539', 'Q_7538'],\n",
       " ['A_3306', 'Q_5396'],\n",
       " ['A_3306', 'R_97958'],\n",
       " ['A_3306', 'Q_5454'],\n",
       " ['A_3306', 'S_5455'],\n",
       " ['Q_5396', 'A_3306'],\n",
       " ['Q_5396', 'R_97958'],\n",
       " ['Q_5396', 'Q_5454'],\n",
       " ['Q_5396', 'S_5455'],\n",
       " ['Q_5396', 'Q_5454'],\n",
       " ['R_97958', 'A_3306'],\n",
       " ['R_97958', 'Q_5396'],\n",
       " ['R_97958', 'Q_5454'],\n",
       " ['R_97958', 'S_5455'],\n",
       " ['R_97958', 'Q_5454'],\n",
       " ['R_97958', 'R_97958'],\n",
       " ['Q_5454', 'A_3306'],\n",
       " ['Q_5454', 'Q_5396'],\n",
       " ['Q_5454', 'R_97958'],\n",
       " ['Q_5454', 'S_5455'],\n",
       " ['Q_5454', 'Q_5454'],\n",
       " ['Q_5454', 'R_97958'],\n",
       " ['Q_5454', 'Q_5396'],\n",
       " ['S_5455', 'A_3306'],\n",
       " ['S_5455', 'Q_5396'],\n",
       " ['S_5455', 'R_97958'],\n",
       " ['S_5455', 'Q_5454'],\n",
       " ['S_5455', 'Q_5454'],\n",
       " ['S_5455', 'R_97958'],\n",
       " ['S_5455', 'Q_5396'],\n",
       " ['S_5455', 'S_5397'],\n",
       " ['Q_5454', 'A_3306'],\n",
       " ['Q_5454', 'Q_5396'],\n",
       " ['Q_5454', 'R_97958'],\n",
       " ['Q_5454', 'Q_5454'],\n",
       " ['Q_5454', 'S_5455'],\n",
       " ['Q_5454', 'R_97958'],\n",
       " ['Q_5454', 'Q_5396'],\n",
       " ['Q_5454', 'S_5397'],\n",
       " ['R_97958', 'Q_5396'],\n",
       " ['R_97958', 'R_97958'],\n",
       " ['R_97958', 'Q_5454'],\n",
       " ['R_97958', 'S_5455'],\n",
       " ['R_97958', 'Q_5454'],\n",
       " ['R_97958', 'Q_5396'],\n",
       " ['R_97958', 'S_5397'],\n",
       " ['Q_5396', 'R_97958'],\n",
       " ['Q_5396', 'Q_5454'],\n",
       " ['Q_5396', 'S_5455'],\n",
       " ['Q_5396', 'Q_5454'],\n",
       " ['Q_5396', 'R_97958'],\n",
       " ['Q_5396', 'S_5397'],\n",
       " ['S_5397', 'Q_5454'],\n",
       " ['S_5397', 'S_5455'],\n",
       " ['S_5397', 'Q_5454'],\n",
       " ['S_5397', 'R_97958'],\n",
       " ['S_5397', 'Q_5396'],\n",
       " ['A_20482', 'Q_2694'],\n",
       " ['A_20482', 'R_21818'],\n",
       " ['A_20482', 'Q_2694'],\n",
       " ['A_20482', 'S_2698'],\n",
       " ['Q_2694', 'A_20482'],\n",
       " ['Q_2694', 'R_21818'],\n",
       " ['Q_2694', 'Q_2694'],\n",
       " ['Q_2694', 'S_2698'],\n",
       " ['Q_2694', 'Q_2694'],\n",
       " ['R_21818', 'A_20482'],\n",
       " ['R_21818', 'Q_2694'],\n",
       " ['R_21818', 'Q_2694'],\n",
       " ['R_21818', 'S_2698'],\n",
       " ['R_21818', 'Q_2694'],\n",
       " ['R_21818', 'R_21818'],\n",
       " ['Q_2694', 'A_20482'],\n",
       " ['Q_2694', 'Q_2694'],\n",
       " ['Q_2694', 'R_21818'],\n",
       " ['Q_2694', 'S_2698'],\n",
       " ['Q_2694', 'Q_2694'],\n",
       " ['Q_2694', 'R_21818'],\n",
       " ['Q_2694', 'Q_2694'],\n",
       " ['S_2698', 'A_20482'],\n",
       " ['S_2698', 'Q_2694'],\n",
       " ['S_2698', 'R_21818'],\n",
       " ['S_2698', 'Q_2694'],\n",
       " ['S_2698', 'Q_2694'],\n",
       " ['S_2698', 'R_21818'],\n",
       " ['S_2698', 'Q_2694'],\n",
       " ['S_2698', 'S_2697'],\n",
       " ['Q_2694', 'A_20482'],\n",
       " ['Q_2694', 'Q_2694'],\n",
       " ['Q_2694', 'R_21818'],\n",
       " ['Q_2694', 'Q_2694'],\n",
       " ['Q_2694', 'S_2698'],\n",
       " ['Q_2694', 'R_21818'],\n",
       " ['Q_2694', 'Q_2694'],\n",
       " ['Q_2694', 'S_2697'],\n",
       " ['R_21818', 'Q_2694'],\n",
       " ['R_21818', 'R_21818'],\n",
       " ['R_21818', 'Q_2694'],\n",
       " ['R_21818', 'S_2698'],\n",
       " ['R_21818', 'Q_2694'],\n",
       " ['R_21818', 'Q_2694'],\n",
       " ['R_21818', 'S_2697'],\n",
       " ['Q_2694', 'R_21818'],\n",
       " ['Q_2694', 'Q_2694'],\n",
       " ['Q_2694', 'S_2698'],\n",
       " ['Q_2694', 'Q_2694'],\n",
       " ['Q_2694', 'R_21818'],\n",
       " ['Q_2694', 'S_2697'],\n",
       " ['S_2697', 'Q_2694'],\n",
       " ['S_2697', 'S_2698'],\n",
       " ['S_2697', 'Q_2694'],\n",
       " ['S_2697', 'R_21818'],\n",
       " ['S_2697', 'Q_2694'],\n",
       " ['A_24531', 'Q_2944'],\n",
       " ['A_24531', 'R_252'],\n",
       " ['A_24531', 'Q_1261'],\n",
       " ['A_24531', 'S_1262'],\n",
       " ['Q_2944', 'A_24531'],\n",
       " ['Q_2944', 'R_252'],\n",
       " ['Q_2944', 'Q_1261'],\n",
       " ['Q_2944', 'S_1262'],\n",
       " ['Q_2944', 'Q_1261'],\n",
       " ['R_252', 'A_24531'],\n",
       " ['R_252', 'Q_2944'],\n",
       " ['R_252', 'Q_1261'],\n",
       " ['R_252', 'S_1262'],\n",
       " ['R_252', 'Q_1261'],\n",
       " ['R_252', 'R_252'],\n",
       " ['Q_1261', 'A_24531'],\n",
       " ['Q_1261', 'Q_2944'],\n",
       " ['Q_1261', 'R_252'],\n",
       " ['Q_1261', 'S_1262'],\n",
       " ['Q_1261', 'Q_1261'],\n",
       " ['Q_1261', 'R_252'],\n",
       " ['Q_1261', 'Q_237'],\n",
       " ['S_1262', 'A_24531'],\n",
       " ['S_1262', 'Q_2944'],\n",
       " ['S_1262', 'R_252'],\n",
       " ['S_1262', 'Q_1261'],\n",
       " ['S_1262', 'Q_1261'],\n",
       " ['S_1262', 'R_252'],\n",
       " ['S_1262', 'Q_237'],\n",
       " ['S_1262', 'S_369'],\n",
       " ['Q_1261', 'A_24531'],\n",
       " ['Q_1261', 'Q_2944'],\n",
       " ['Q_1261', 'R_252'],\n",
       " ['Q_1261', 'Q_1261'],\n",
       " ['Q_1261', 'S_1262'],\n",
       " ['Q_1261', 'R_252'],\n",
       " ['Q_1261', 'Q_237'],\n",
       " ['Q_1261', 'S_369'],\n",
       " ['R_252', 'Q_2944'],\n",
       " ['R_252', 'R_252'],\n",
       " ['R_252', 'Q_1261'],\n",
       " ['R_252', 'S_1262'],\n",
       " ['R_252', 'Q_1261'],\n",
       " ['R_252', 'Q_237'],\n",
       " ['R_252', 'S_369'],\n",
       " ['Q_237', 'R_252'],\n",
       " ['Q_237', 'Q_1261'],\n",
       " ['Q_237', 'S_1262'],\n",
       " ['Q_237', 'Q_1261'],\n",
       " ['Q_237', 'R_252'],\n",
       " ['Q_237', 'S_369'],\n",
       " ['S_369', 'Q_1261'],\n",
       " ['S_369', 'S_1262'],\n",
       " ['S_369', 'Q_1261'],\n",
       " ['S_369', 'R_252'],\n",
       " ['S_369', 'Q_237'],\n",
       " ['A_87794', 'Q_4582'],\n",
       " ['A_87794', 'R_58761'],\n",
       " ['A_87794', 'Q_7183'],\n",
       " ['A_87794', 'S_7186'],\n",
       " ['Q_4582', 'A_87794'],\n",
       " ['Q_4582', 'R_58761'],\n",
       " ['Q_4582', 'Q_7183'],\n",
       " ['Q_4582', 'S_7186'],\n",
       " ['Q_4582', 'Q_7183'],\n",
       " ['R_58761', 'A_87794'],\n",
       " ['R_58761', 'Q_4582'],\n",
       " ['R_58761', 'Q_7183'],\n",
       " ['R_58761', 'S_7186'],\n",
       " ['R_58761', 'Q_7183'],\n",
       " ['R_58761', 'R_58761'],\n",
       " ['Q_7183', 'A_87794'],\n",
       " ['Q_7183', 'Q_4582'],\n",
       " ['Q_7183', 'R_58761'],\n",
       " ['Q_7183', 'S_7186'],\n",
       " ['Q_7183', 'Q_7183'],\n",
       " ['Q_7183', 'R_58761'],\n",
       " ['Q_7183', 'Q_7183'],\n",
       " ['S_7186', 'A_87794'],\n",
       " ['S_7186', 'Q_4582'],\n",
       " ['S_7186', 'R_58761'],\n",
       " ['S_7186', 'Q_7183'],\n",
       " ['S_7186', 'Q_7183'],\n",
       " ['S_7186', 'R_58761'],\n",
       " ['S_7186', 'Q_7183'],\n",
       " ['S_7186', 'S_7186'],\n",
       " ['Q_7183', 'A_87794'],\n",
       " ['Q_7183', 'Q_4582'],\n",
       " ['Q_7183', 'R_58761'],\n",
       " ['Q_7183', 'Q_7183'],\n",
       " ['Q_7183', 'S_7186'],\n",
       " ['Q_7183', 'R_58761'],\n",
       " ['Q_7183', 'Q_7183'],\n",
       " ['Q_7183', 'S_7186'],\n",
       " ['R_58761', 'Q_4582'],\n",
       " ['R_58761', 'R_58761'],\n",
       " ['R_58761', 'Q_7183'],\n",
       " ['R_58761', 'S_7186'],\n",
       " ['R_58761', 'Q_7183'],\n",
       " ['R_58761', 'Q_7183'],\n",
       " ['R_58761', 'S_7186'],\n",
       " ['Q_7183', 'R_58761'],\n",
       " ['Q_7183', 'Q_7183'],\n",
       " ['Q_7183', 'S_7186'],\n",
       " ['Q_7183', 'Q_7183'],\n",
       " ['Q_7183', 'R_58761'],\n",
       " ['Q_7183', 'S_7186'],\n",
       " ['S_7186', 'Q_7183'],\n",
       " ['S_7186', 'S_7186'],\n",
       " ['S_7186', 'Q_7183'],\n",
       " ['S_7186', 'R_58761'],\n",
       " ['S_7186', 'Q_7183'],\n",
       " ['A_47827', 'Q_5420'],\n",
       " ['A_47827', 'R_2085'],\n",
       " ['A_47827', 'Q_6682'],\n",
       " ['A_47827', 'S_6744'],\n",
       " ['Q_5420', 'A_47827'],\n",
       " ['Q_5420', 'R_2085'],\n",
       " ['Q_5420', 'Q_6682'],\n",
       " ['Q_5420', 'S_6744'],\n",
       " ['Q_5420', 'Q_6682'],\n",
       " ['R_2085', 'A_47827'],\n",
       " ['R_2085', 'Q_5420'],\n",
       " ['R_2085', 'Q_6682'],\n",
       " ['R_2085', 'S_6744'],\n",
       " ['R_2085', 'Q_6682'],\n",
       " ['R_2085', 'R_2085'],\n",
       " ['Q_6682', 'A_47827'],\n",
       " ['Q_6682', 'Q_5420'],\n",
       " ['Q_6682', 'R_2085'],\n",
       " ['Q_6682', 'S_6744'],\n",
       " ['Q_6682', 'Q_6682'],\n",
       " ['Q_6682', 'R_2085'],\n",
       " ['Q_6682', 'Q_4973'],\n",
       " ['S_6744', 'A_47827'],\n",
       " ['S_6744', 'Q_5420'],\n",
       " ['S_6744', 'R_2085'],\n",
       " ['S_6744', 'Q_6682'],\n",
       " ['S_6744', 'Q_6682'],\n",
       " ['S_6744', 'R_2085'],\n",
       " ['S_6744', 'Q_4973'],\n",
       " ['S_6744', 'S_4974'],\n",
       " ['Q_6682', 'A_47827'],\n",
       " ['Q_6682', 'Q_5420'],\n",
       " ['Q_6682', 'R_2085'],\n",
       " ['Q_6682', 'Q_6682'],\n",
       " ['Q_6682', 'S_6744'],\n",
       " ['Q_6682', 'R_2085'],\n",
       " ['Q_6682', 'Q_4973'],\n",
       " ['Q_6682', 'S_4974'],\n",
       " ['R_2085', 'Q_5420'],\n",
       " ['R_2085', 'R_2085'],\n",
       " ['R_2085', 'Q_6682'],\n",
       " ['R_2085', 'S_6744'],\n",
       " ['R_2085', 'Q_6682'],\n",
       " ['R_2085', 'Q_4973'],\n",
       " ['R_2085', 'S_4974'],\n",
       " ['Q_4973', 'R_2085'],\n",
       " ['Q_4973', 'Q_6682'],\n",
       " ['Q_4973', 'S_6744'],\n",
       " ['Q_4973', 'Q_6682'],\n",
       " ['Q_4973', 'R_2085'],\n",
       " ['Q_4973', 'S_4974'],\n",
       " ['S_4974', 'Q_6682'],\n",
       " ['S_4974', 'S_6744'],\n",
       " ['S_4974', 'Q_6682'],\n",
       " ['S_4974', 'R_2085'],\n",
       " ['S_4974', 'Q_4973'],\n",
       " ['A_6300', 'Q_951'],\n",
       " ['A_6300', 'R_252'],\n",
       " ['A_6300', 'Q_1029'],\n",
       " ['A_6300', 'S_1031'],\n",
       " ['Q_951', 'A_6300'],\n",
       " ['Q_951', 'R_252'],\n",
       " ['Q_951', 'Q_1029'],\n",
       " ['Q_951', 'S_1031'],\n",
       " ['Q_951', 'Q_1029'],\n",
       " ['R_252', 'A_6300'],\n",
       " ['R_252', 'Q_951'],\n",
       " ['R_252', 'Q_1029'],\n",
       " ['R_252', 'S_1031'],\n",
       " ['R_252', 'Q_1029'],\n",
       " ['R_252', 'R_252'],\n",
       " ['Q_1029', 'A_6300'],\n",
       " ['Q_1029', 'Q_951'],\n",
       " ['Q_1029', 'R_252'],\n",
       " ['Q_1029', 'S_1031'],\n",
       " ['Q_1029', 'Q_1029'],\n",
       " ['Q_1029', 'R_252'],\n",
       " ['Q_1029', 'Q_3333'],\n",
       " ['S_1031', 'A_6300'],\n",
       " ['S_1031', 'Q_951'],\n",
       " ['S_1031', 'R_252'],\n",
       " ['S_1031', 'Q_1029'],\n",
       " ['S_1031', 'Q_1029'],\n",
       " ['S_1031', 'R_252'],\n",
       " ['S_1031', 'Q_3333'],\n",
       " ['S_1031', 'S_3337'],\n",
       " ['Q_1029', 'A_6300'],\n",
       " ['Q_1029', 'Q_951'],\n",
       " ['Q_1029', 'R_252'],\n",
       " ['Q_1029', 'Q_1029'],\n",
       " ['Q_1029', 'S_1031'],\n",
       " ['Q_1029', 'R_252'],\n",
       " ['Q_1029', 'Q_3333'],\n",
       " ['Q_1029', 'S_3337'],\n",
       " ['R_252', 'Q_951'],\n",
       " ['R_252', 'R_252'],\n",
       " ['R_252', 'Q_1029'],\n",
       " ['R_252', 'S_1031'],\n",
       " ['R_252', 'Q_1029'],\n",
       " ['R_252', 'Q_3333'],\n",
       " ['R_252', 'S_3337'],\n",
       " ['Q_3333', 'R_252'],\n",
       " ['Q_3333', 'Q_1029'],\n",
       " ['Q_3333', 'S_1031'],\n",
       " ['Q_3333', 'Q_1029'],\n",
       " ['Q_3333', 'R_252'],\n",
       " ['Q_3333', 'S_3337'],\n",
       " ['S_3337', 'Q_1029'],\n",
       " ['S_3337', 'S_1031'],\n",
       " ['S_3337', 'Q_1029'],\n",
       " ['S_3337', 'R_252'],\n",
       " ['S_3337', 'Q_3333'],\n",
       " ['A_3438', 'Q_815'],\n",
       " ['A_3438', 'R_3479'],\n",
       " ['A_3438', 'Q_815'],\n",
       " ['A_3438', 'S_819'],\n",
       " ['Q_815', 'A_3438'],\n",
       " ['Q_815', 'R_3479'],\n",
       " ['Q_815', 'Q_815'],\n",
       " ['Q_815', 'S_819'],\n",
       " ['Q_815', 'Q_815'],\n",
       " ['R_3479', 'A_3438'],\n",
       " ['R_3479', 'Q_815'],\n",
       " ['R_3479', 'Q_815'],\n",
       " ['R_3479', 'S_819'],\n",
       " ['R_3479', 'Q_815'],\n",
       " ['R_3479', 'R_3479'],\n",
       " ['Q_815', 'A_3438'],\n",
       " ['Q_815', 'Q_815'],\n",
       " ['Q_815', 'R_3479'],\n",
       " ['Q_815', 'S_819'],\n",
       " ['Q_815', 'Q_815'],\n",
       " ['Q_815', 'R_3479'],\n",
       " ['Q_815', 'Q_601'],\n",
       " ['S_819', 'A_3438'],\n",
       " ['S_819', 'Q_815'],\n",
       " ['S_819', 'R_3479'],\n",
       " ['S_819', 'Q_815'],\n",
       " ['S_819', 'Q_815'],\n",
       " ['S_819', 'R_3479'],\n",
       " ['S_819', 'Q_601'],\n",
       " ['S_819', 'S_603'],\n",
       " ['Q_815', 'A_3438'],\n",
       " ['Q_815', 'Q_815'],\n",
       " ['Q_815', 'R_3479'],\n",
       " ['Q_815', 'Q_815'],\n",
       " ['Q_815', 'S_819'],\n",
       " ['Q_815', 'R_3479'],\n",
       " ['Q_815', 'Q_601'],\n",
       " ['Q_815', 'S_603'],\n",
       " ['R_3479', 'Q_815'],\n",
       " ['R_3479', 'R_3479'],\n",
       " ['R_3479', 'Q_815'],\n",
       " ['R_3479', 'S_819'],\n",
       " ['R_3479', 'Q_815'],\n",
       " ['R_3479', 'Q_601'],\n",
       " ['R_3479', 'S_603'],\n",
       " ['Q_601', 'R_3479'],\n",
       " ['Q_601', 'Q_815'],\n",
       " ['Q_601', 'S_819'],\n",
       " ['Q_601', 'Q_815'],\n",
       " ['Q_601', 'R_3479'],\n",
       " ['Q_601', 'S_603'],\n",
       " ['S_603', 'Q_815'],\n",
       " ['S_603', 'S_819'],\n",
       " ['S_603', 'Q_815'],\n",
       " ['S_603', 'R_3479'],\n",
       " ['S_603', 'Q_601'],\n",
       " ['A_55623', 'Q_13460'],\n",
       " ['A_55623', 'R_362933'],\n",
       " ['A_55623', 'Q_13458'],\n",
       " ['A_55623', 'S_13461'],\n",
       " ['Q_13460', 'A_55623'],\n",
       " ['Q_13460', 'R_362933'],\n",
       " ['Q_13460', 'Q_13458'],\n",
       " ['Q_13460', 'S_13461'],\n",
       " ['Q_13460', 'Q_13458'],\n",
       " ['R_362933', 'A_55623'],\n",
       " ['R_362933', 'Q_13460'],\n",
       " ['R_362933', 'Q_13458'],\n",
       " ['R_362933', 'S_13461'],\n",
       " ['R_362933', 'Q_13458'],\n",
       " ['R_362933', 'R_362933'],\n",
       " ['Q_13458', 'A_55623'],\n",
       " ['Q_13458', 'Q_13460'],\n",
       " ['Q_13458', 'R_362933'],\n",
       " ['Q_13458', 'S_13461'],\n",
       " ['Q_13458', 'Q_13458'],\n",
       " ['Q_13458', 'R_362933'],\n",
       " ['Q_13458', 'Q_13458'],\n",
       " ['S_13461', 'A_55623'],\n",
       " ['S_13461', 'Q_13460'],\n",
       " ['S_13461', 'R_362933'],\n",
       " ['S_13461', 'Q_13458'],\n",
       " ['S_13461', 'Q_13458'],\n",
       " ['S_13461', 'R_362933'],\n",
       " ['S_13461', 'Q_13458'],\n",
       " ['S_13461', 'S_13461'],\n",
       " ['Q_13458', 'A_55623'],\n",
       " ['Q_13458', 'Q_13460'],\n",
       " ['Q_13458', 'R_362933'],\n",
       " ['Q_13458', 'Q_13458'],\n",
       " ['Q_13458', 'S_13461'],\n",
       " ['Q_13458', 'R_362933'],\n",
       " ['Q_13458', 'Q_13458'],\n",
       " ['Q_13458', 'S_13461'],\n",
       " ['R_362933', 'Q_13460'],\n",
       " ['R_362933', 'R_362933'],\n",
       " ['R_362933', 'Q_13458'],\n",
       " ['R_362933', 'S_13461'],\n",
       " ['R_362933', 'Q_13458'],\n",
       " ['R_362933', 'Q_13458'],\n",
       " ['R_362933', 'S_13461'],\n",
       " ['Q_13458', 'R_362933'],\n",
       " ['Q_13458', 'Q_13458'],\n",
       " ['Q_13458', 'S_13461'],\n",
       " ['Q_13458', 'Q_13458'],\n",
       " ['Q_13458', 'R_362933'],\n",
       " ['Q_13458', 'S_13461'],\n",
       " ['S_13461', 'Q_13458'],\n",
       " ['S_13461', 'S_13461'],\n",
       " ['S_13461', 'Q_13458'],\n",
       " ['S_13461', 'R_362933'],\n",
       " ['S_13461', 'Q_13458'],\n",
       " ['A_1778', 'Q_163'],\n",
       " ['A_1778', 'R_303'],\n",
       " ['A_1778', 'Q_163'],\n",
       " ['A_1778', 'S_188'],\n",
       " ['Q_163', 'A_1778'],\n",
       " ['Q_163', 'R_303'],\n",
       " ['Q_163', 'Q_163'],\n",
       " ['Q_163', 'S_188'],\n",
       " ['Q_163', 'Q_163'],\n",
       " ['R_303', 'A_1778'],\n",
       " ['R_303', 'Q_163'],\n",
       " ['R_303', 'Q_163'],\n",
       " ['R_303', 'S_188'],\n",
       " ['R_303', 'Q_163'],\n",
       " ['R_303', 'R_303'],\n",
       " ['Q_163', 'A_1778'],\n",
       " ['Q_163', 'Q_163'],\n",
       " ['Q_163', 'R_303'],\n",
       " ['Q_163', 'S_188'],\n",
       " ['Q_163', 'Q_163'],\n",
       " ['Q_163', 'R_303'],\n",
       " ['Q_163', 'Q_163'],\n",
       " ['S_188', 'A_1778'],\n",
       " ['S_188', 'Q_163'],\n",
       " ['S_188', 'R_303'],\n",
       " ['S_188', 'Q_163'],\n",
       " ['S_188', 'Q_163'],\n",
       " ['S_188', 'R_303'],\n",
       " ['S_188', 'Q_163'],\n",
       " ['S_188', 'S_188'],\n",
       " ['Q_163', 'A_1778'],\n",
       " ['Q_163', 'Q_163'],\n",
       " ['Q_163', 'R_303'],\n",
       " ['Q_163', 'Q_163'],\n",
       " ['Q_163', 'S_188'],\n",
       " ['Q_163', 'R_303'],\n",
       " ['Q_163', 'Q_163'],\n",
       " ['Q_163', 'S_188'],\n",
       " ['R_303', 'Q_163'],\n",
       " ['R_303', 'R_303'],\n",
       " ['R_303', 'Q_163'],\n",
       " ['R_303', 'S_188'],\n",
       " ['R_303', 'Q_163'],\n",
       " ['R_303', 'Q_163'],\n",
       " ['R_303', 'S_188'],\n",
       " ['Q_163', 'R_303'],\n",
       " ['Q_163', 'Q_163'],\n",
       " ['Q_163', 'S_188'],\n",
       " ['Q_163', 'Q_163'],\n",
       " ['Q_163', 'R_303'],\n",
       " ['Q_163', 'S_188'],\n",
       " ['S_188', 'Q_163'],\n",
       " ['S_188', 'S_188'],\n",
       " ['S_188', 'Q_163'],\n",
       " ['S_188', 'R_303'],\n",
       " ['S_188', 'Q_163'],\n",
       " ['A_5432', 'Q_904'],\n",
       " ['A_5432', 'R_3036'],\n",
       " ['A_5432', 'Q_490'],\n",
       " ['A_5432', 'S_492'],\n",
       " ['Q_904', 'A_5432'],\n",
       " ['Q_904', 'R_3036'],\n",
       " ['Q_904', 'Q_490'],\n",
       " ['Q_904', 'S_492'],\n",
       " ['Q_904', 'Q_490'],\n",
       " ['R_3036', 'A_5432'],\n",
       " ['R_3036', 'Q_904'],\n",
       " ['R_3036', 'Q_490'],\n",
       " ['R_3036', 'S_492'],\n",
       " ['R_3036', 'Q_490'],\n",
       " ['R_3036', 'R_3036'],\n",
       " ['Q_490', 'A_5432'],\n",
       " ['Q_490', 'Q_904'],\n",
       " ['Q_490', 'R_3036'],\n",
       " ['Q_490', 'S_492'],\n",
       " ['Q_490', 'Q_490'],\n",
       " ['Q_490', 'R_3036'],\n",
       " ['Q_490', 'Q_765'],\n",
       " ['S_492', 'A_5432'],\n",
       " ['S_492', 'Q_904'],\n",
       " ['S_492', 'R_3036'],\n",
       " ['S_492', 'Q_490'],\n",
       " ['S_492', 'Q_490'],\n",
       " ['S_492', 'R_3036'],\n",
       " ['S_492', 'Q_765'],\n",
       " ['S_492', 'S_772'],\n",
       " ['Q_490', 'A_5432'],\n",
       " ['Q_490', 'Q_904'],\n",
       " ['Q_490', 'R_3036'],\n",
       " ['Q_490', 'Q_490'],\n",
       " ['Q_490', 'S_492'],\n",
       " ['Q_490', 'R_3036'],\n",
       " ['Q_490', 'Q_765'],\n",
       " ['Q_490', 'S_772'],\n",
       " ['R_3036', 'Q_904'],\n",
       " ['R_3036', 'R_3036'],\n",
       " ['R_3036', 'Q_490'],\n",
       " ['R_3036', 'S_492'],\n",
       " ['R_3036', 'Q_490'],\n",
       " ['R_3036', 'Q_765'],\n",
       " ['R_3036', 'S_772'],\n",
       " ['Q_765', 'R_3036'],\n",
       " ['Q_765', 'Q_490'],\n",
       " ['Q_765', 'S_492'],\n",
       " ['Q_765', 'Q_490'],\n",
       " ['Q_765', 'R_3036'],\n",
       " ['Q_765', 'S_772'],\n",
       " ['S_772', 'Q_490'],\n",
       " ['S_772', 'S_492'],\n",
       " ['S_772', 'Q_490'],\n",
       " ['S_772', 'R_3036'],\n",
       " ['S_772', 'Q_765'],\n",
       " ['A_28544', 'Q_1513'],\n",
       " ['A_28544', 'R_252'],\n",
       " ['A_28544', 'Q_862'],\n",
       " ['A_28544', 'S_863'],\n",
       " ['Q_1513', 'A_28544'],\n",
       " ['Q_1513', 'R_252'],\n",
       " ['Q_1513', 'Q_862'],\n",
       " ['Q_1513', 'S_863'],\n",
       " ['Q_1513', 'Q_862'],\n",
       " ['R_252', 'A_28544'],\n",
       " ['R_252', 'Q_1513'],\n",
       " ['R_252', 'Q_862'],\n",
       " ['R_252', 'S_863'],\n",
       " ['R_252', 'Q_862'],\n",
       " ['R_252', 'R_252'],\n",
       " ['Q_862', 'A_28544'],\n",
       " ['Q_862', 'Q_1513'],\n",
       " ['Q_862', 'R_252'],\n",
       " ['Q_862', 'S_863'],\n",
       " ['Q_862', 'Q_862'],\n",
       " ['Q_862', 'R_252'],\n",
       " ['Q_862', 'Q_209'],\n",
       " ['S_863', 'A_28544'],\n",
       " ['S_863', 'Q_1513'],\n",
       " ['S_863', 'R_252'],\n",
       " ['S_863', 'Q_862'],\n",
       " ['S_863', 'Q_862'],\n",
       " ['S_863', 'R_252'],\n",
       " ['S_863', 'Q_209'],\n",
       " ['S_863', 'S_219'],\n",
       " ['Q_862', 'A_28544'],\n",
       " ['Q_862', 'Q_1513'],\n",
       " ['Q_862', 'R_252'],\n",
       " ['Q_862', 'Q_862'],\n",
       " ['Q_862', 'S_863'],\n",
       " ['Q_862', 'R_252'],\n",
       " ['Q_862', 'Q_209'],\n",
       " ['Q_862', 'S_219'],\n",
       " ['R_252', 'Q_1513'],\n",
       " ['R_252', 'R_252'],\n",
       " ['R_252', 'Q_862'],\n",
       " ['R_252', 'S_863'],\n",
       " ['R_252', 'Q_862'],\n",
       " ['R_252', 'Q_209'],\n",
       " ['R_252', 'S_219'],\n",
       " ['Q_209', 'R_252'],\n",
       " ['Q_209', 'Q_862'],\n",
       " ['Q_209', 'S_863'],\n",
       " ['Q_209', 'Q_862'],\n",
       " ['Q_209', 'R_252'],\n",
       " ['Q_209', 'S_219'],\n",
       " ['S_219', 'Q_862'],\n",
       " ['S_219', 'S_863'],\n",
       " ['S_219', 'Q_862'],\n",
       " ['S_219', 'R_252'],\n",
       " ['S_219', 'Q_209'],\n",
       " ['A_227655', 'Q_11461'],\n",
       " ['A_227655', 'R_298438'],\n",
       " ['A_227655', 'Q_11461'],\n",
       " ['A_227655', 'S_11462'],\n",
       " ['Q_11461', 'A_227655'],\n",
       " ['Q_11461', 'R_298438'],\n",
       " ['Q_11461', 'Q_11461'],\n",
       " ['Q_11461', 'S_11462'],\n",
       " ['Q_11461', 'Q_11461'],\n",
       " ['R_298438', 'A_227655'],\n",
       " ['R_298438', 'Q_11461'],\n",
       " ['R_298438', 'Q_11461'],\n",
       " ['R_298438', 'S_11462'],\n",
       " ['R_298438', 'Q_11461'],\n",
       " ['R_298438', 'R_298438'],\n",
       " ['Q_11461', 'A_227655'],\n",
       " ['Q_11461', 'Q_11461'],\n",
       " ['Q_11461', 'R_298438'],\n",
       " ['Q_11461', 'S_11462'],\n",
       " ['Q_11461', 'Q_11461'],\n",
       " ['Q_11461', 'R_298438'],\n",
       " ['Q_11461', 'Q_11461'],\n",
       " ['S_11462', 'A_227655'],\n",
       " ['S_11462', 'Q_11461'],\n",
       " ['S_11462', 'R_298438'],\n",
       " ['S_11462', 'Q_11461'],\n",
       " ['S_11462', 'Q_11461'],\n",
       " ['S_11462', 'R_298438'],\n",
       " ['S_11462', 'Q_11461'],\n",
       " ['S_11462', 'S_11462'],\n",
       " ['Q_11461', 'A_227655'],\n",
       " ['Q_11461', 'Q_11461'],\n",
       " ['Q_11461', 'R_298438'],\n",
       " ['Q_11461', 'Q_11461'],\n",
       " ['Q_11461', 'S_11462'],\n",
       " ['Q_11461', 'R_298438'],\n",
       " ['Q_11461', 'Q_11461'],\n",
       " ['Q_11461', 'S_11462'],\n",
       " ['R_298438', 'Q_11461'],\n",
       " ['R_298438', 'R_298438'],\n",
       " ['R_298438', 'Q_11461'],\n",
       " ['R_298438', 'S_11462'],\n",
       " ['R_298438', 'Q_11461'],\n",
       " ['R_298438', 'Q_11461'],\n",
       " ['R_298438', 'S_11462'],\n",
       " ['Q_11461', 'R_298438'],\n",
       " ['Q_11461', 'Q_11461'],\n",
       " ['Q_11461', 'S_11462'],\n",
       " ['Q_11461', 'Q_11461'],\n",
       " ['Q_11461', 'R_298438'],\n",
       " ['Q_11461', 'S_11462'],\n",
       " ['S_11462', 'Q_11461'],\n",
       " ['S_11462', 'S_11462'],\n",
       " ['S_11462', 'Q_11461'],\n",
       " ['S_11462', 'R_298438'],\n",
       " ['S_11462', 'Q_11461'],\n",
       " ['A_1637', 'Q_557'],\n",
       " ['A_1637', 'R_2303'],\n",
       " ['A_1637', 'Q_9730'],\n",
       " ['A_1637', 'S_9731'],\n",
       " ['Q_557', 'A_1637'],\n",
       " ['Q_557', 'R_2303'],\n",
       " ['Q_557', 'Q_9730'],\n",
       " ['Q_557', 'S_9731'],\n",
       " ['Q_557', 'Q_9730'],\n",
       " ['R_2303', 'A_1637'],\n",
       " ['R_2303', 'Q_557'],\n",
       " ['R_2303', 'Q_9730'],\n",
       " ['R_2303', 'S_9731'],\n",
       " ['R_2303', 'Q_9730'],\n",
       " ['R_2303', 'R_2303'],\n",
       " ['Q_9730', 'A_1637'],\n",
       " ['Q_9730', 'Q_557'],\n",
       " ['Q_9730', 'R_2303'],\n",
       " ['Q_9730', 'S_9731'],\n",
       " ['Q_9730', 'Q_9730'],\n",
       " ['Q_9730', 'R_2303'],\n",
       " ['Q_9730', 'Q_1649'],\n",
       " ['S_9731', 'A_1637'],\n",
       " ['S_9731', 'Q_557'],\n",
       " ['S_9731', 'R_2303'],\n",
       " ['S_9731', 'Q_9730'],\n",
       " ['S_9731', 'Q_9730'],\n",
       " ['S_9731', 'R_2303'],\n",
       " ['S_9731', 'Q_1649'],\n",
       " ['S_9731', 'S_1650'],\n",
       " ['Q_9730', 'A_1637'],\n",
       " ['Q_9730', 'Q_557'],\n",
       " ['Q_9730', 'R_2303'],\n",
       " ['Q_9730', 'Q_9730'],\n",
       " ['Q_9730', 'S_9731'],\n",
       " ['Q_9730', 'R_2303'],\n",
       " ['Q_9730', 'Q_1649'],\n",
       " ['Q_9730', 'S_1650'],\n",
       " ['R_2303', 'Q_557'],\n",
       " ['R_2303', 'R_2303'],\n",
       " ['R_2303', 'Q_9730'],\n",
       " ['R_2303', 'S_9731'],\n",
       " ['R_2303', 'Q_9730'],\n",
       " ['R_2303', 'Q_1649'],\n",
       " ['R_2303', 'S_1650'],\n",
       " ['Q_1649', 'R_2303'],\n",
       " ['Q_1649', 'Q_9730'],\n",
       " ['Q_1649', 'S_9731'],\n",
       " ...]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 3, 2: 1, 3: 1, 4: 1})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([1,1,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000000.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=Counter({1: 3, 2: 1, 3: 1, 4: 1})\n",
    "count = [ele[1] for ele in self.count]\n",
    "pow_freq = np.array(count) ** 0.75\n",
    "ratio = pow_freq / sum(pow_freq)\n",
    "table_size = 2e7 # todo: what is this???\n",
    "count = np.round(ratio * table_size).astype(np.int64)\n",
    "sample_table = []\n",
    "\n",
    "for i in range(len(self.count)):\n",
    "    sample_table += [self.count[i][0]] * count[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=Counter({1: 3, 2: 1, 3: 1, 4: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=Counter.most_common(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 3), (2, 1), (3, 1), (4, 1)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_table = []\n",
    "count=[1,3,4,5]\n",
    "for i in range(len(a)):\n",
    "    sample_table += [a[i][0]] * count[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=1\n",
    "[a[i][0]] * count[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = {}\n",
    "counter = Counter()\n",
    "for line in gw.walks:\n",
    "    line = line.strip().split(\" \")\n",
    "    counter.update(line)\n",
    "a=counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def __init_sample_table(a):\n",
    "    \"\"\"\n",
    "    create sample tables by p()^(3/4)\n",
    "\n",
    "    return:\n",
    "        (sample_table)  -  the created sample table\n",
    "    \"\"\"\n",
    "    count = [ele[1] for ele in a]\n",
    "    pow_freq = np.array(count) ** 0.75\n",
    "    ratio = pow_freq / sum(pow_freq)\n",
    "    table_size = 200000 # todo: what is this???\n",
    "    count = np.round(ratio * table_size).astype(np.int64)\n",
    "    sample_table = []\n",
    "\n",
    "    for i in range(len(a)):\n",
    "        sample_table += [a[i][0]] * count[i]\n",
    "    return np.array(sample_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7f10f8f2c6e0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(*[[1,3],[2,3],[4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,v=zip(*[[1,3],[2,3],[4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 4)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = {\"A\": 1, \"Q\": 2, \"R\": 0,\"S\":3}\n",
    "sep = np.zeros(shape=(4, len(entity_seq)))\n",
    "for index, item in enumerate(entity_seq):\n",
    "    split = item.split(\"_\")\n",
    "    ent_type, ent_id = D[split[0]], int(split[1])\n",
    "    sep[ent_type][index] = ent_id\n",
    "#return sep.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep.astype(np.int64).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0.,      0.,  61075.,      0.,      0.,      0.,  61075.,\n",
       "             0.,      0.],\n",
       "       [184706.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.],\n",
       "       [     0.,   9371.,      0.,   9371.,      0.,   9371.,      0.,\n",
       "          9386.,      0.],\n",
       "       [     0.,      0.,      0.,      0.,   9374.,      0.,      0.,\n",
       "             0.,   9387.]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=gw.walks[0].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A_184706',\n",
       " 'Q_9371',\n",
       " 'R_61075',\n",
       " 'Q_9371',\n",
       " 'S_9374',\n",
       " 'Q_9371',\n",
       " 'R_61075',\n",
       " 'Q_9386',\n",
       " 'S_9387']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_seq=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "aid_samples=list([\"111\"])\n",
    "more_ans = np.random.choice(a, replace=False,\n",
    "                            size=16 - len(a))\n",
    "aid_samples += list(more_ans) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['111',\n",
       " 'S_9387',\n",
       " 'Q_9371',\n",
       " 'Q_9371',\n",
       " 'Q_9386',\n",
       " 'R_61075',\n",
       " 'R_61075',\n",
       " 'A_184706']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aid_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "if a:\n",
    "    print(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( [[0.0] * 300 for _ in range(200)][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=Counter({1: 3, 2: 1, 3: 1, 4: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 3, 2: 1, 3: 1, 4: 1})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=[1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-c555fc016922>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "if q:\n",
    "    a[q].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=list(['a','b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "question='a b c a a b fd s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = [x for x in question.strip().split(\" \")\n",
    "              if x in v]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'a', 'a', 'b']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if question:\n",
    "    qvecs = self.w2vmodel[question].tolist()\n",
    "    q_len = len(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "PATH = \"GoogleNews-vectors-negative300.bin\"\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "    fname=PATH, binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=['the','panda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type((model[question]).tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qvlen = Variable(torch.LongTensor(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    139874355735712,     139874355735712,                   0,\n",
       "                          0,                   1,      93854824136920,\n",
       "                          1,      93854824136576, 2314885530279477276,\n",
       "            139874271168688,                   2,     139872584770305,\n",
       "                          1,         -4294967268,     139874326054448,\n",
       "                -4294967295,     139872585295664,         34359738369,\n",
       "                          1,      93854824136824])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qvlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "qulen = qvlen.unsqueeze(1).expand(-1, 256).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 256])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qulen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 2],\n",
       "        [3, 1],\n",
       "        [7, 4],\n",
       "        [1, 1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "input = [\n",
    "    [2, 3, 4, 5, 0, 0],\n",
    "    [1, 4, 3, 0, 0, 0],\n",
    "    [4, 2, 2, 5, 7, 0],\n",
    "    [1, 0, 0, 0, 0, 0]\n",
    "]\n",
    "input = torch.tensor(input)\n",
    "#注意index的类型\n",
    "length = torch.LongTensor([[4,1],[3,1],[5,1],[1,1]])\n",
    "#index之所以减1,是因为序列维度是从0开始计算的\n",
    "out = torch.gather(input, 1, length-1)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
